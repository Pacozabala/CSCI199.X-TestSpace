{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO2TL/2K6gcmAN/HJsT+5q1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pacozabala/CSCI199.X-TestSpace/blob/main/data_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements to run\n",
        "1. TAS-BERT requires GPU, so please change your runtime to GPU.\n",
        "2. On the first code block, upload your kaggle API key."
      ],
      "metadata": {
        "id": "8UWRUb0C96UJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "HUG2lmzwYzoG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "c1a8d3d2-6e5d-4c6a-95ae-b0510b2c9aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a111c66f-dc5f-48b5-8d60-c592c9b5d068\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a111c66f-dc5f-48b5-8d60-c592c9b5d068\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"pacozabala\",\"key\":\"4bddcfaf7d7419eabf3e18b02f90de83\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d asaniczka/reddit-on-israel-palestine-daily-updated\n",
        "!unzip reddit-on-israel-palestine-daily-updated.zip"
      ],
      "metadata": {
        "id": "ChxjG4CjY-xD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85da0b35-c8f7-4a98-ab7d-de02bbcb7df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/asaniczka/reddit-on-israel-palestine-daily-updated\n",
            "License(s): ODC Attribution License (ODC-By)\n",
            "Downloading reddit-on-israel-palestine-daily-updated.zip to /content\n",
            " 95% 1.20G/1.27G [00:16<00:02, 29.4MB/s]\n",
            "100% 1.27G/1.27G [00:17<00:00, 80.0MB/s]\n",
            "Archive:  reddit-on-israel-palestine-daily-updated.zip\n",
            "  inflating: legacy/pse_isr_reddit_comments.csv  \n",
            "  inflating: reddit_opinion_PSE_ISR.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "63HJpvAqcG6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"reddit_opinion_PSE_ISR.csv\", dtype={10: str})"
      ],
      "metadata": {
        "id": "fmmZGhY-POoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "j_tYJzYp1r-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aa25263-a94e-4cb3-c269-6de1a29b6429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3476679 entries, 0 to 3476678\n",
            "Data columns (total 24 columns):\n",
            " #   Column                      Dtype  \n",
            "---  ------                      -----  \n",
            " 0   comment_id                  object \n",
            " 1   score                       int64  \n",
            " 2   self_text                   object \n",
            " 3   subreddit                   object \n",
            " 4   created_time                object \n",
            " 5   post_id                     object \n",
            " 6   author_name                 object \n",
            " 7   controversiality            int64  \n",
            " 8   ups                         int64  \n",
            " 9   downs                       int64  \n",
            " 10  user_is_verified            object \n",
            " 11  user_account_created_time   object \n",
            " 12  user_awardee_karma          float64\n",
            " 13  user_awarder_karma          float64\n",
            " 14  user_link_karma             float64\n",
            " 15  user_comment_karma          float64\n",
            " 16  user_total_karma            float64\n",
            " 17  post_score                  int64  \n",
            " 18  post_self_text              object \n",
            " 19  post_title                  object \n",
            " 20  post_upvote_ratio           float64\n",
            " 21  post_thumbs_ups             int64  \n",
            " 22  post_total_awards_received  int64  \n",
            " 23  post_created_time           object \n",
            "dtypes: float64(6), int64(7), object(11)\n",
            "memory usage: 636.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter between Oct and Dec 2023\n",
        "df['post_created_time'] = pd.to_datetime(df['post_created_time'])\n",
        "\n",
        "start_date = pd.to_datetime('2023-10-01')\n",
        "end_date = pd.to_datetime('2023-12-31')\n",
        "\n",
        "df_dated = df[\n",
        "    (df['post_created_time'] >= start_date) &\n",
        "    (df['post_created_time'] <= end_date)\n",
        "]\n",
        "\n",
        "print(df_dated['post_created_time'].min())\n",
        "print(df_dated['post_created_time'].max())"
      ],
      "metadata": {
        "id": "Zx_qjQr7Ay87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3849d54-86e6-44d0-a44f-f407d7aa991c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-01 10:52:13\n",
            "2023-12-30 23:20:36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out posts from underrepresented subreddits\n",
        "subreddit_counts = df_dated['subreddit'].value_counts()\n",
        "valid_subreddits = subreddit_counts[subreddit_counts >= 1000].index\n",
        "df_dated = df_dated[df_dated['subreddit'].isin(valid_subreddits)]\n",
        "df_dated.info()"
      ],
      "metadata": {
        "id": "wP-BEQOwQecu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc361f0c-ad78-4cd0-da17-654307947a20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 577116 entries, 2881774 to 3474681\n",
            "Data columns (total 24 columns):\n",
            " #   Column                      Non-Null Count   Dtype         \n",
            "---  ------                      --------------   -----         \n",
            " 0   comment_id                  577116 non-null  object        \n",
            " 1   score                       577116 non-null  int64         \n",
            " 2   self_text                   577113 non-null  object        \n",
            " 3   subreddit                   577116 non-null  object        \n",
            " 4   created_time                577116 non-null  object        \n",
            " 5   post_id                     577116 non-null  object        \n",
            " 6   author_name                 577116 non-null  object        \n",
            " 7   controversiality            577116 non-null  int64         \n",
            " 8   ups                         577116 non-null  int64         \n",
            " 9   downs                       577116 non-null  int64         \n",
            " 10  user_is_verified            577116 non-null  object        \n",
            " 11  user_account_created_time   543460 non-null  object        \n",
            " 12  user_awardee_karma          577070 non-null  float64       \n",
            " 13  user_awarder_karma          577070 non-null  float64       \n",
            " 14  user_link_karma             577070 non-null  float64       \n",
            " 15  user_comment_karma          577070 non-null  float64       \n",
            " 16  user_total_karma            577070 non-null  float64       \n",
            " 17  post_score                  577116 non-null  int64         \n",
            " 18  post_self_text              277403 non-null  object        \n",
            " 19  post_title                  577116 non-null  object        \n",
            " 20  post_upvote_ratio           577116 non-null  float64       \n",
            " 21  post_thumbs_ups             577116 non-null  int64         \n",
            " 22  post_total_awards_received  577116 non-null  int64         \n",
            " 23  post_created_time           577116 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), float64(6), int64(7), object(10)\n",
            "memory usage: 110.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter out null values\n",
        "df_dated = df_dated.dropna(subset=['post_self_text'])\n",
        "display(df_dated[['post_self_text']].head())"
      ],
      "metadata": {
        "id": "rNBZVzsIExXM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "019d4757-765d-4580-94d5-c1b4902a34a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            post_self_text\n",
              "2881774  Are you counting the 8-17 year olds that have ...\n",
              "2885666  Hello everyone, I hope you all are doing well....\n",
              "2885704  After 54 days in captivity- Mia Schem had been...\n",
              "2885720  Discussion is going to be centralized here.\\n\\...\n",
              "2885743  After 54 days in captivity- Mia Schem had been..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9797fab8-d582-420c-83b7-e2110bffbbbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_self_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2881774</th>\n",
              "      <td>Are you counting the 8-17 year olds that have ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2885666</th>\n",
              "      <td>Hello everyone, I hope you all are doing well....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2885704</th>\n",
              "      <td>After 54 days in captivity- Mia Schem had been...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2885720</th>\n",
              "      <td>Discussion is going to be centralized here.\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2885743</th>\n",
              "      <td>After 54 days in captivity- Mia Schem had been...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9797fab8-d582-420c-83b7-e2110bffbbbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9797fab8-d582-420c-83b7-e2110bffbbbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9797fab8-d582-420c-83b7-e2110bffbbbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-88ae74ec-84a2-4038-90d6-21d30796e334\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88ae74ec-84a2-4038-90d6-21d30796e334')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-88ae74ec-84a2-4038-90d6-21d30796e334 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_dated[['post_self_text']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"post_self_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Hello everyone, I hope you all are doing well. I have a hypothetical question that I would like to ask the pro Palestinian side about how I am curious about the following scenario and how your prospective would change: when israel had left Gaza in 2005 (I believe it was around that timeframe) what if Palestinians had elected a good government that not only started to do but prioritized on maintaining peace and a better relationship diplomatically with Israel and building infrastructure and city\\u2019s instead of focusing on all out war and destruction upon Israel, do you think the people of Gaza/Palestine today be living in a more peaceful, prosperous, and enriching environment? or even the bare minimum of this situation , if the Palestinians had invested in SOME defense rather than total offense or even if Hamas focused on attacking Israel in ways that would minimize civilian casualties when Israel retaliates, do you think we\\u2019d see such as high death toll as we a hearing about today, and would the Palestinians live somewhat better lives, atleast anything better then what there experiencing now, I am trying to see things from a pro Palestinian perspective as i personally beleive the root cause of this many civilians getting hurt or worse is not Israel as i beleive from those who have went to war with Israel besides Palestine much less civilians deaths (i believe) were reported, I understand Palestine is very crowded but still. and I would appreciate your thoughts on how things would then be different! And I\\u2019d like to add how meeting the minimum amount of characters to post this question was not fun!\",\n          \"Discussion is going to be centralized here.\\n\\nModeration will be tight - rule breaking, name calling, racism, etc will result in permanent ban.\",\n          \"Are you counting the 8-17 year olds that have been brainwashed to hate jews to kill jews, to die for \\\"palestine\\\" \\nThe \\\"children\\\" that are part of hamas, that able to shoot and bomb. \\nThe \\\"children\\\" who came into isreal on Oct 7th to kill and rape civilians\\nThe \\\"children\\\" who spat and kicked at isreali hostages taken into gaza\\n Most- if not all of these SO CALLED CHILDREN are not innocent, they are not civilians, they cannot be considered as normal children!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "966d364d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "outputId": "eb531f7a-63d2-483d-8c17-f8f38460805c"
      },
      "source": [
        "# get a random sample of 1000\n",
        "df_sample = df_dated.sample(n=100, random_state=42) # using a random state for reproducibility\n",
        "display(df_sample.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        comment_id  score                                          self_text  \\\n",
              "3311851    k9om2n4      0  &gt;Smoking gun evidence won’t be released unt...   \n",
              "2947282    keq6tl4      4                            Banned in Iran already.   \n",
              "3074349    kclhvks      1  The UN is a kangaroo court.  Israel should be ...   \n",
              "3373906    k8zu7nh      4    The replies are there for you to read yourself.   \n",
              "3058333    kcsis97      4  If you actually cared about \"vile, depraved\" w...   \n",
              "\n",
              "               subreddit         created_time  post_id           author_name  \\\n",
              "3311851  IsraelPalestine  2023-11-17 20:49:23  17xgmy0  CulturalCranberry960   \n",
              "2947282  IsraelPalestine  2023-12-24 10:45:45  18plfym       Less-Plant-4099   \n",
              "3074349  IsraelPalestine  2023-12-09 04:45:49  18drn6w               jwilens   \n",
              "3373906  IsraelPalestine  2023-11-12 23:23:15  17tizfn              mikebenb   \n",
              "3058333  IsraelPalestine  2023-12-10 18:02:50  18f8k0d            AhsokaSolo   \n",
              "\n",
              "         controversiality  ups  downs  ... user_link_karma user_comment_karma  \\\n",
              "3311851                 0    0      0  ...            53.0              348.0   \n",
              "2947282                 0    4      0  ...             1.0             5209.0   \n",
              "3074349                 0    1      0  ...           110.0             1682.0   \n",
              "3373906                 0    4      0  ...           507.0            15810.0   \n",
              "3058333                 0    4      0  ...             1.0            64980.0   \n",
              "\n",
              "         user_total_karma  post_score  \\\n",
              "3311851             401.0          35   \n",
              "2947282            5210.0          28   \n",
              "3074349            1800.0          76   \n",
              "3373906           16455.0          59   \n",
              "3058333           64981.0           0   \n",
              "\n",
              "                                            post_self_text  \\\n",
              "3311851  editors note: if you liked my article segment,...   \n",
              "2947282  Found this free simulation game from 2006 that...   \n",
              "3074349  I've been following this account on Twitter (s...   \n",
              "3373906  Is exposing people's true feelings about Jews....   \n",
              "3058333  Although I strongly disagree that being a pos ...   \n",
              "\n",
              "                                                post_title  post_upvote_ratio  \\\n",
              "3311851  The IDF says they have found an “operational H...               0.75   \n",
              "2947282            Peacemaker: Peace Simulation Video Game               0.92   \n",
              "3074349  The casualty numbers in Gaza are completely fa...               0.60   \n",
              "3373906                  The only think to thank Hamas for               0.71   \n",
              "3058333  I have a question for those who think that any...               0.35   \n",
              "\n",
              "         post_thumbs_ups post_total_awards_received   post_created_time  \n",
              "3311851               35                          0 2023-11-17 14:45:41  \n",
              "2947282               28                          0 2023-12-24 02:33:08  \n",
              "3074349               76                          0 2023-12-08 17:17:37  \n",
              "3373906               59                          0 2023-11-12 12:10:57  \n",
              "3058333                0                          0 2023-12-10 17:28:43  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0d210e3-7f7d-45c4-b12c-b0ca431d1844\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_id</th>\n",
              "      <th>score</th>\n",
              "      <th>self_text</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>created_time</th>\n",
              "      <th>post_id</th>\n",
              "      <th>author_name</th>\n",
              "      <th>controversiality</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>...</th>\n",
              "      <th>user_link_karma</th>\n",
              "      <th>user_comment_karma</th>\n",
              "      <th>user_total_karma</th>\n",
              "      <th>post_score</th>\n",
              "      <th>post_self_text</th>\n",
              "      <th>post_title</th>\n",
              "      <th>post_upvote_ratio</th>\n",
              "      <th>post_thumbs_ups</th>\n",
              "      <th>post_total_awards_received</th>\n",
              "      <th>post_created_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3311851</th>\n",
              "      <td>k9om2n4</td>\n",
              "      <td>0</td>\n",
              "      <td>&amp;gt;Smoking gun evidence won’t be released unt...</td>\n",
              "      <td>IsraelPalestine</td>\n",
              "      <td>2023-11-17 20:49:23</td>\n",
              "      <td>17xgmy0</td>\n",
              "      <td>CulturalCranberry960</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>53.0</td>\n",
              "      <td>348.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>35</td>\n",
              "      <td>editors note: if you liked my article segment,...</td>\n",
              "      <td>The IDF says they have found an “operational H...</td>\n",
              "      <td>0.75</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-11-17 14:45:41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2947282</th>\n",
              "      <td>keq6tl4</td>\n",
              "      <td>4</td>\n",
              "      <td>Banned in Iran already.</td>\n",
              "      <td>IsraelPalestine</td>\n",
              "      <td>2023-12-24 10:45:45</td>\n",
              "      <td>18plfym</td>\n",
              "      <td>Less-Plant-4099</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5209.0</td>\n",
              "      <td>5210.0</td>\n",
              "      <td>28</td>\n",
              "      <td>Found this free simulation game from 2006 that...</td>\n",
              "      <td>Peacemaker: Peace Simulation Video Game</td>\n",
              "      <td>0.92</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-12-24 02:33:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3074349</th>\n",
              "      <td>kclhvks</td>\n",
              "      <td>1</td>\n",
              "      <td>The UN is a kangaroo court.  Israel should be ...</td>\n",
              "      <td>IsraelPalestine</td>\n",
              "      <td>2023-12-09 04:45:49</td>\n",
              "      <td>18drn6w</td>\n",
              "      <td>jwilens</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>110.0</td>\n",
              "      <td>1682.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>76</td>\n",
              "      <td>I've been following this account on Twitter (s...</td>\n",
              "      <td>The casualty numbers in Gaza are completely fa...</td>\n",
              "      <td>0.60</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-12-08 17:17:37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3373906</th>\n",
              "      <td>k8zu7nh</td>\n",
              "      <td>4</td>\n",
              "      <td>The replies are there for you to read yourself.</td>\n",
              "      <td>IsraelPalestine</td>\n",
              "      <td>2023-11-12 23:23:15</td>\n",
              "      <td>17tizfn</td>\n",
              "      <td>mikebenb</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>507.0</td>\n",
              "      <td>15810.0</td>\n",
              "      <td>16455.0</td>\n",
              "      <td>59</td>\n",
              "      <td>Is exposing people's true feelings about Jews....</td>\n",
              "      <td>The only think to thank Hamas for</td>\n",
              "      <td>0.71</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-11-12 12:10:57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3058333</th>\n",
              "      <td>kcsis97</td>\n",
              "      <td>4</td>\n",
              "      <td>If you actually cared about \"vile, depraved\" w...</td>\n",
              "      <td>IsraelPalestine</td>\n",
              "      <td>2023-12-10 18:02:50</td>\n",
              "      <td>18f8k0d</td>\n",
              "      <td>AhsokaSolo</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>64980.0</td>\n",
              "      <td>64981.0</td>\n",
              "      <td>0</td>\n",
              "      <td>Although I strongly disagree that being a pos ...</td>\n",
              "      <td>I have a question for those who think that any...</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2023-12-10 17:28:43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0d210e3-7f7d-45c4-b12c-b0ca431d1844')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0d210e3-7f7d-45c4-b12c-b0ca431d1844 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0d210e3-7f7d-45c4-b12c-b0ca431d1844');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dafa144b-6750-44f4-8cb1-1580eaa7647e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dafa144b-6750-44f4-8cb1-1580eaa7647e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dafa144b-6750-44f4-8cb1-1580eaa7647e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning text\n",
        "# remove html tags, user mentions, subreddit references\n",
        "\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # 1. remove HTML tags, CSS styles\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "    # 2. remove user mentions like \"u/username\"\n",
        "    text = re.sub(r\"u/[A-Za-z0-9_-]+\", \"\", text)\n",
        "\n",
        "    # 3. remove subreddit mentions\"\n",
        "    text = re.sub(r\"r/[A-Za-z0-9_-]+\", \"\", text)\n",
        "\n",
        "    # 4. remove URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "\n",
        "    # 5. remove whitespace and line breaks\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    # 6. lowercase text\n",
        "    text = text.lower()\n",
        "\n",
        "    # 7. remove punctuation, but keep periods, question marks, and exclamation points\n",
        "    text = re.sub(r\"[^\\w\\s.?!]\", \"\", text)\n",
        "\n",
        "    return text\n",
        "df_cleaned = df_sample.copy()\n",
        "df_cleaned['cleaned_text'] = df_sample['post_self_text'].apply(clean_text)\n",
        "display(df_cleaned[['post_self_text', 'cleaned_text']].head(10))"
      ],
      "metadata": {
        "id": "O9ImUb7MFpkP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "da9eaca7-f9c7-4f71-d3b1-2d1da8397e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            post_self_text  \\\n",
              "3311851  editors note: if you liked my article segment,...   \n",
              "2947282  Found this free simulation game from 2006 that...   \n",
              "3074349  I've been following this account on Twitter (s...   \n",
              "3373906  Is exposing people's true feelings about Jews....   \n",
              "3058333  Although I strongly disagree that being a pos ...   \n",
              "3012086  Discussion is going to be centralized here.\\n\\...   \n",
              "3165579  Prime Minister Benjamin Netanyahu has reported...   \n",
              "3104922  What is happening in the palestinian territori...   \n",
              "3027945  Background then question:\\n\\n I didn’t realize...   \n",
              "3054959  It’s crazy to me that Hamas attacked on Octobe...   \n",
              "\n",
              "                                              cleaned_text  \n",
              "3311851  editors note if you liked my article segment c...  \n",
              "2947282  found this free simulation game from 2006 that...  \n",
              "3074349  ive been following this account on twitter sor...  \n",
              "3373906  is exposing peoples true feelings about jews. ...  \n",
              "3058333  although i strongly disagree that being a pos ...  \n",
              "3012086  discussion is going to be centralized here. mo...  \n",
              "3165579  prime minister benjamin netanyahu has reported...  \n",
              "3104922  what is happening in the palestinian territori...  \n",
              "3027945  background then question i didnt realize i was...  \n",
              "3054959  its crazy to me that hamas attacked on october...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c369bd85-08e5-48e9-8ab3-9399a2ab1b2d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>post_self_text</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3311851</th>\n",
              "      <td>editors note: if you liked my article segment,...</td>\n",
              "      <td>editors note if you liked my article segment c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2947282</th>\n",
              "      <td>Found this free simulation game from 2006 that...</td>\n",
              "      <td>found this free simulation game from 2006 that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3074349</th>\n",
              "      <td>I've been following this account on Twitter (s...</td>\n",
              "      <td>ive been following this account on twitter sor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3373906</th>\n",
              "      <td>Is exposing people's true feelings about Jews....</td>\n",
              "      <td>is exposing peoples true feelings about jews. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3058333</th>\n",
              "      <td>Although I strongly disagree that being a pos ...</td>\n",
              "      <td>although i strongly disagree that being a pos ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3012086</th>\n",
              "      <td>Discussion is going to be centralized here.\\n\\...</td>\n",
              "      <td>discussion is going to be centralized here. mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3165579</th>\n",
              "      <td>Prime Minister Benjamin Netanyahu has reported...</td>\n",
              "      <td>prime minister benjamin netanyahu has reported...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3104922</th>\n",
              "      <td>What is happening in the palestinian territori...</td>\n",
              "      <td>what is happening in the palestinian territori...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3027945</th>\n",
              "      <td>Background then question:\\n\\n I didn’t realize...</td>\n",
              "      <td>background then question i didnt realize i was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3054959</th>\n",
              "      <td>It’s crazy to me that Hamas attacked on Octobe...</td>\n",
              "      <td>its crazy to me that hamas attacked on october...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c369bd85-08e5-48e9-8ab3-9399a2ab1b2d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c369bd85-08e5-48e9-8ab3-9399a2ab1b2d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c369bd85-08e5-48e9-8ab3-9399a2ab1b2d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-391de907-9323-4c0e-994b-597304e74117\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-391de907-9323-4c0e-994b-597304e74117')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-391de907-9323-4c0e-994b-597304e74117 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_cleaned[['post_self_text', 'cleaned_text']]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"post_self_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Background then question:\\n\\n I didn\\u2019t realize I was \\u201cpro-Israel\\u201d until after 10/7 when I found out to my dismay that my left-leaning friends were either pro-Hamas or justifying Hamas\\u2019 actions and also thought that the \\u201ccolonial settler state of Israel\\u201d needed to be destroyed.  I am aware of many criticisms of Israeli policy and am willing to have a conversation about any of them, provided the person does not defend or excuse the actions of Hamas on 10/7 and provided the person can at least see that calling for the destruction of Israel is at least de facto calling for a genocide against Jews.  So I\\u2019m pretty open to criticizing Israeli policy and how it wages war.\\n\\nThe question I have is, has anyone else noticed the vague and inaccurate language being used by pro-Hamas and pro-Palestinian people ?  I spend most of the time when speaking with these people trying to get them to define their terms and then seeing them move the goal posts when cornered.  \\u201cGenocide,\\u201d \\u201ccarpet bombing,\\u201d \\u201ccolonialist,\\u201d \\u201capartheid,\\u201d \\u201cracism,\\u201d etc: none of these words are being used correctly or accurately and It makes it impossible to have a real conversation. It seems like the words are chosen for their emotional impact rather than their accuracy. They also seem to obfuscate what \\u201cfrom the river to the sea,\\u201d \\u201cglobalize the intifada\\u201d etc actually mean which makes me feel like I\\u2019m not dealing with people being honest about heir intentions, I\\u2019m very frustrated by this because I think there is a genuine conversation to have but it\\u2019s not really possible to have it. Question is, do others share this experience and what\\u2019s the way forward if this is a generalizable experience?\",\n          \"Found this free simulation game from 2006 that's still fun to play now, and as a gamer it gives me a shred of hope to hang on to.  And it's fun!\\n\\nYou play as either the Israeli prime minister or the Palestinian president and your goal is to bring about a permanent peace.\\n\\nI played as the Israeli PM.  You can take various actions like send the IDF to secure an area, increase or decrease security checkpoints, encourage economic development, talk to the Palestinian president, talk to the United States, make speeches, crack down on settlers etc.\\n\\nThe two key game mechanics are Israeli approval rating and Palestinian approval rating.  Both start at 0 and to win you have to raise *both* to 100.  You lose if *either* falls to -50.\\n\\nIDF actions raise Israeli approval but lower Palestinian approval, but sometimes, you have to take strong action against Hamas in order to deter violence.  I got better results from covert assassination of terrorists than from overt military strikes.  Once, I had the IDF launch a missile strike to take out a Hamas building.  It knocked back their terror abilities, but the US was upset and the Pal president wouldn't talk to me for a while.\\n\\nOne thing that increased Pal approval without costing Israeli approval was giving Pals medical aid and economic development.  And after building trust with the Pals, I asked the Pal president for assistance against militants, and he agreed, which increased approval with both Israelis and Pals.\\n\\nI was able to win, but my violence score was 302, which is not so good.  I think that missile strike cost me more than it gained.  I'd like to try again and see if I can achieve peace with less violence.\\n\\nGive it a try and see if you can beat my score.\\n\\n[http://www.peacemakergame.com/](http://www.peacemakergame.com/)\\n\\n&amp;#x200B;\",\n          \"Discussion is going to be centralized here.\\n\\nModeration will be tight - rule breaking, name calling, racism, etc will result in permanent ban.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"background then question i didnt realize i was proisrael until after 107 when i found out to my dismay that my leftleaning friends were either prohamas or justifying hamas actions and also thought that the colonial settler state of israel needed to be destroyed. i am aware of many criticisms of israeli policy and am willing to have a conversation about any of them provided the person does not defend or excuse the actions of hamas on 107 and provided the person can at least see that calling for the destruction of israel is at least de facto calling for a genocide against jews. so im pretty open to criticizing israeli policy and how it wages war. the question i have is has anyone else noticed the vague and inaccurate language being used by prohamas and propalestinian people ? i spend most of the time when speaking with these people trying to get them to define their terms and then seeing them move the goal posts when cornered. genocide carpet bombing colonialist apartheid racism etc none of these words are being used correctly or accurately and it makes it impossible to have a real conversation. it seems like the words are chosen for their emotional impact rather than their accuracy. they also seem to obfuscate what from the river to the sea globalize the intifada etc actually mean which makes me feel like im not dealing with people being honest about heir intentions im very frustrated by this because i think there is a genuine conversation to have but its not really possible to have it. question is do others share this experience and whats the way forward if this is a generalizable experience?\",\n          \"found this free simulation game from 2006 thats still fun to play now and as a gamer it gives me a shred of hope to hang on to. and its fun! you play as either the israeli prime minister or the palestinian president and your goal is to bring about a permanent peace. i played as the israeli pm. you can take various actions like send the idf to secure an area increase or decrease security checkpoints encourage economic development talk to the palestinian president talk to the united states make speeches crack down on settlers etc. the two key game mechanics are israeli approval rating and palestinian approval rating. both start at 0 and to win you have to raise both to 100. you lose if either falls to 50. idf actions raise israeli approval but lower palestinian approval but sometimes you have to take strong action against hamas in order to deter violence. i got better results from covert assassination of terrorists than from overt military strikes. once i had the idf launch a missile strike to take out a hamas building. it knocked back their terror abilities but the us was upset and the pal president wouldnt talk to me for a while. one thing that increased pal approval without costing israeli approval was giving pals medical aid and economic development. and after building trust with the pals i asked the pal president for assistance against militants and he agreed which increased approval with both israelis and pals. i was able to win but my violence score was 302 which is not so good. i think that missile strike cost me more than it gained. id like to try again and see if i can achieve peace with less violence. give it a try and see if you can beat my score.  x200b\",\n          \"discussion is going to be centralized here. moderation will be tight  rule breaking name calling racism etc will result in permanent ban.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c49b802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca4c5b2-78ed-4ca9-d8ae-81569f6c5d49"
      },
      "source": [
        "# get needed columns\n",
        "df_column = df_cleaned[['cleaned_text']]\n",
        "df_column.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 100 entries, 3311851 to 2942716\n",
            "Data columns (total 1 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   cleaned_text  100 non-null    object\n",
            "dtypes: object(1)\n",
            "memory usage: 1.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a348087",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "720567d6-d440-41dc-85f2-5b3292127621"
      },
      "source": [
        "# eliminate duplicates\n",
        "df_unique = df_column.drop_duplicates(subset=['cleaned_text'])\n",
        "display(df_unique.info())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 95 entries, 3311851 to 2942716\n",
            "Data columns (total 1 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   cleaned_text  95 non-null     object\n",
            "dtypes: object(1)\n",
            "memory usage: 1.5+ KB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "001db774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "96a2dfc2-cff9-4933-d3d3-e8bc950c6dbb"
      },
      "source": [
        "# sentence segmentation and punctuation removal\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import string\n",
        "\n",
        "# Download all 'punkt' related resources if they haven't already been downloaded\n",
        "try:\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('punkt_tab', quiet=True)\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading 'punkt' resources: {e}\")\n",
        "\n",
        "\n",
        "def segment_and_clean_sentences(text):\n",
        "    if pd.isna(text):\n",
        "        return []\n",
        "    sentences = sent_tokenize(text)\n",
        "    cleaned_sentences = []\n",
        "    for sentence in sentences:\n",
        "        # Remove all punctuation from the sentence\n",
        "        sentence_no_punct = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "        cleaned_sentences.append(sentence_no_punct)\n",
        "    return cleaned_sentences\n",
        "\n",
        "# Create a new list to store the individual sentences\n",
        "sentences_list = []\n",
        "for index, row in df_unique.iterrows():\n",
        "    cleaned_sentences = segment_and_clean_sentences(row['cleaned_text'])\n",
        "    for sentence in cleaned_sentences:\n",
        "        sentences_list.append({'sentence': sentence})\n",
        "\n",
        "# Create a new DataFrame from the list of sentences\n",
        "df_sentences = pd.DataFrame(sentences_list)\n",
        "display(df_sentences.head())\n",
        "df_sentences.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            sentence\n",
              "0  editors note if you liked my article segment c...\n",
              "1  reported by cnn the israel defense forces idf ...\n",
              "2  a video released by the idf displays a substan...\n",
              "3  however there was no footage supplied of the c...\n",
              "4  idf spokesman daniel hagari said army engineer..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28770bb3-6ac0-4962-96f4-8f2d408860e6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>editors note if you liked my article segment c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>reported by cnn the israel defense forces idf ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a video released by the idf displays a substan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>however there was no footage supplied of the c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>idf spokesman daniel hagari said army engineer...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28770bb3-6ac0-4962-96f4-8f2d408860e6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-28770bb3-6ac0-4962-96f4-8f2d408860e6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-28770bb3-6ac0-4962-96f4-8f2d408860e6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c1801023-858d-4069-8795-1586d55becdd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c1801023-858d-4069-8795-1586d55becdd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c1801023-858d-4069-8795-1586d55becdd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_sentences\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"reported by cnn the israel defense forces idf recently released footage of an operational hamas tunnel near alshifa hospital\",\n          \"idf spokesman daniel hagari said army engineers were still working to expose the tunnel infrastructure\",\n          \"a video released by the idf displays a substantial hole in the ground situated around 30 meters from the hospitals main building\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1094 entries, 0 to 1093\n",
            "Data columns (total 1 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   sentence  1094 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 8.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset columns\n",
        "# sentence_id: Unique ID for each sentence\n",
        "# sentence: The text (can have leading space)\n",
        "# target: The aspect target term (or \"NULL\" if implicit)\n",
        "# category: The aspect category (e.g., \"food quality\", \"service general\")\n",
        "# polarity: positive/negative/neutral\n",
        "# category_polarity: category + space + polarity\n",
        "# entailed: \"yes\" if this row represents an actual opinion, \"no\" otherwise\n",
        "# start: 1-based word index where target starts (0 for NULL)\n",
        "# end: 1-based word index where target ends (0 for NULL)"
      ],
      "metadata": {
        "id": "uoFms9WBvmi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mock data generation\n",
        "mft_categories = [\n",
        "    \"care/harm\", \"fairness/cheating\", \"loyalty/betrayal\",\n",
        "    \"authority/subversion\", \"purity/degradation\", \"none\"\n",
        "]\n",
        "polarities = [\"positive\", \"negative\", \"neutral\"]\n",
        "\n",
        "data = []\n",
        "\n",
        "for i, row in df_sentences.iterrows():\n",
        "    # Ensure consistent spacing (TAS-BERT tokenizes on spaces)\n",
        "    sentence = \" \".join(row[\"sentence\"].strip().split())\n",
        "\n",
        "    # Randomly assign category and polarity\n",
        "    category = random.choice(mft_categories)\n",
        "    polarity = random.choice(polarities)\n",
        "    category_polarity = f\"{category} {polarity}\"\n",
        "\n",
        "    # 70% explicit targets, 30% implicit\n",
        "    entailed = \"yes\" if random.random() > 0.3 else \"no\"\n",
        "\n",
        "    if entailed == \"yes\":\n",
        "        words = sentence.split()\n",
        "        if len(words) > 3:\n",
        "            # Randomly select a span\n",
        "            span_length = random.randint(1, min(3, len(words)))\n",
        "            start = random.randint(1, len(words) - span_length + 1)\n",
        "            end = start + span_length  # end is EXCLUSIVE for TAS-BERT\n",
        "            target = \" \".join(words[start - 1:end - 1])  # match TAS-BERT slicing\n",
        "        else:\n",
        "            start, end, target = 0, 0, \"NULL\"\n",
        "    else:\n",
        "        start, end, target = 0, 0, \"NULL\"\n",
        "\n",
        "    sentence_id = f\"{1000000 + i}:0\"\n",
        "    data.append({\n",
        "        \"sentence_id\": sentence_id,\n",
        "        \"sentence\": sentence,\n",
        "        \"target\": target,\n",
        "        \"category\": category,\n",
        "        \"polarity\": polarity,\n",
        "        \"category_polarity\": category_polarity,\n",
        "        \"entailed\": entailed,\n",
        "        \"start\": start,\n",
        "        \"end\": end\n",
        "    })\n",
        "\n",
        "df_mock = pd.DataFrame(data)\n",
        "df_mock.head()\n"
      ],
      "metadata": {
        "id": "B5QSwu-Z1AqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "424163e0-ca69-4c12-e9da-e2273b4801e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  sentence_id                                           sentence  \\\n",
              "0   1000000:0  editors note if you liked my article segment c...   \n",
              "1   1000001:0  reported by cnn the israel defense forces idf ...   \n",
              "2   1000002:0  a video released by the idf displays a substan...   \n",
              "3   1000003:0  however there was no footage supplied of the c...   \n",
              "4   1000004:0  idf spokesman daniel hagari said army engineer...   \n",
              "\n",
              "            target              category  polarity  \\\n",
              "0             NULL  authority/subversion  negative   \n",
              "1  reported by cnn  authority/subversion  positive   \n",
              "2           ground    purity/degradation  positive   \n",
              "3           of the      loyalty/betrayal  positive   \n",
              "4             NULL    purity/degradation  positive   \n",
              "\n",
              "               category_polarity entailed  start  end  \n",
              "0  authority/subversion negative       no      0    0  \n",
              "1  authority/subversion positive      yes      1    4  \n",
              "2    purity/degradation positive      yes     13   14  \n",
              "3      loyalty/betrayal positive      yes      7    9  \n",
              "4    purity/degradation positive       no      0    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7725f847-87fe-4b17-b78e-81329ad3a80a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>target</th>\n",
              "      <th>category</th>\n",
              "      <th>polarity</th>\n",
              "      <th>category_polarity</th>\n",
              "      <th>entailed</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000000:0</td>\n",
              "      <td>editors note if you liked my article segment c...</td>\n",
              "      <td>NULL</td>\n",
              "      <td>authority/subversion</td>\n",
              "      <td>negative</td>\n",
              "      <td>authority/subversion negative</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000001:0</td>\n",
              "      <td>reported by cnn the israel defense forces idf ...</td>\n",
              "      <td>reported by cnn</td>\n",
              "      <td>authority/subversion</td>\n",
              "      <td>positive</td>\n",
              "      <td>authority/subversion positive</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000002:0</td>\n",
              "      <td>a video released by the idf displays a substan...</td>\n",
              "      <td>ground</td>\n",
              "      <td>purity/degradation</td>\n",
              "      <td>positive</td>\n",
              "      <td>purity/degradation positive</td>\n",
              "      <td>yes</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000003:0</td>\n",
              "      <td>however there was no footage supplied of the c...</td>\n",
              "      <td>of the</td>\n",
              "      <td>loyalty/betrayal</td>\n",
              "      <td>positive</td>\n",
              "      <td>loyalty/betrayal positive</td>\n",
              "      <td>yes</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000004:0</td>\n",
              "      <td>idf spokesman daniel hagari said army engineer...</td>\n",
              "      <td>NULL</td>\n",
              "      <td>purity/degradation</td>\n",
              "      <td>positive</td>\n",
              "      <td>purity/degradation positive</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7725f847-87fe-4b17-b78e-81329ad3a80a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7725f847-87fe-4b17-b78e-81329ad3a80a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7725f847-87fe-4b17-b78e-81329ad3a80a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-81d43e45-539e-434a-9848-ea6376920945\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81d43e45-539e-434a-9848-ea6376920945')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-81d43e45-539e-434a-9848-ea6376920945 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_mock",
              "summary": "{\n  \"name\": \"df_mock\",\n  \"rows\": 1094,\n  \"fields\": [\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1094,\n        \"samples\": [\n          \"1000482:0\",\n          \"1000139:0\",\n          \"1000088:0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1074,\n        \"samples\": [\n          \"they were showing proof of the idfs efforts to preserve civilian lives\",\n          \"what should happen after the war\",\n          \"the attack forced staff to evacuate the next day leaving babies that could not be transported alone in intensive care according to doctors without borders\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 670,\n        \"samples\": [\n          \"israel committing war\",\n          \"loyal and compliant\",\n          \"ridiculous proposition\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"authority/subversion\",\n          \"purity/degradation\",\n          \"fairness/cheating\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"negative\",\n          \"positive\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category_polarity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"authority/subversion negative\",\n          \"authority/subversion positive\",\n          \"fairness/cheating negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"entailed\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 0,\n        \"max\": 119,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          6,\n          26\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 0,\n        \"max\": 121,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          60,\n          32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4b15eb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fba606b-c506-4eea-9849-5847b9250004"
      },
      "source": [
        "# shuffle dataframe\n",
        "df_shuffled = df_mock.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# calculate split point\n",
        "split_point = int(len(df_shuffled) * 0.8)\n",
        "\n",
        "# split into training and testing sets\n",
        "df_train = df_shuffled[:split_point]\n",
        "df_test = df_shuffled[split_point:]\n",
        "\n",
        "# save to CSV files\n",
        "df_train.to_csv('df_mock_train.csv', index=False)\n",
        "df_test.to_csv('df_mock_test.csv', index=False)\n",
        "\n",
        "# save also as TSV\n",
        "df_train.to_csv('df_mock_train.tsv', index=False, sep='\\t')\n",
        "df_test.to_csv('df_mock_test.tsv', index=False, sep='\\t')\n",
        "\n",
        "print(\"Training set shape:\", df_train.shape)\n",
        "print(\"Test set shape:\", df_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (875, 9)\n",
            "Test set shape: (219, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run before here!"
      ],
      "metadata": {
        "id": "gN3DndUgFN9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3af1b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd96aea-521e-4b5e-9e5a-da759f9cec69"
      },
      "source": [
        "# clone TAS-BERT repo\n",
        "# I forked TAS-BERT so it could take in a custom dataset, but only mock_data for now.\n",
        "!git clone https://github.com/Pacozabala/TAS-BERT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TAS-BERT'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 82 (delta 13), reused 9 (delta 8), pack-reused 61 (from 1)\u001b[K\n",
            "Receiving objects: 100% (82/82), 789.99 KiB | 11.62 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install pytorch-crf dependency\n",
        "!pip install pytorch-crf\n",
        "import torchcrf\n",
        "print(\"torchcrf imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbTbXFSGAKDt",
        "outputId": "e7f80daa-e112-42d3-96d7-625f14f6972d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-crf\n",
            "  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n",
            "torchcrf imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download uncased BERT model\n",
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip -o uncased_L-12_H-768_A-12.zip -d TAS-BERT/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MrigOamAYXq",
        "outputId": "cc76c3a8-ee96-44a6-ade9-88a7fbd9a545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-11 09:54:39--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.210.207, 74.125.26.207, 173.194.212.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.210.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   136MB/s    in 2.9s    \n",
            "\n",
            "2025-11-11 09:54:42 (136 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: TAS-BERT/uncased_L-12_H-768_A-12/\n",
            "  inflating: TAS-BERT/uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: TAS-BERT/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: TAS-BERT/uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: TAS-BERT/uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: TAS-BERT/uncased_L-12_H-768_A-12/bert_config.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# command to create BERT-pytorch-model\n",
        "!python TAS-BERT/convert_tf_checkpoint_to_pytorch.py \\\n",
        "--tf_checkpoint_path TAS-BERT/uncased_L-12_H-768_A-12/bert_model.ckpt \\\n",
        "--bert_config_file TAS-BERT/uncased_L-12_H-768_A-12/bert_config.json \\\n",
        "--pytorch_dump_path TAS-BERT/uncased_L-12_H-768_A-12/pytorch_model.bin"
      ],
      "metadata": {
        "id": "QgTXvMEKAmeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c058466e-c8b1-401a-d149-a8e00fa111c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-11 09:55:00.857389: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762854901.321088    2722 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762854901.426515    2722 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762854902.300241    2722 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762854902.300285    2722 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762854902.300292    2722 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762854902.300298    2722 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-11 09:55:02.397734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Converting TensorFlow checkpoint from TAS-BERT/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "Loading bert/embeddings/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/embeddings/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/embeddings/position_embeddings with shape [512, 768]\n",
            "Numpy array shape (512, 768)\n",
            "Loading bert/embeddings/token_type_embeddings with shape [2, 768]\n",
            "Numpy array shape (2, 768)\n",
            "Loading bert/embeddings/word_embeddings with shape [30522, 768]\n",
            "2025-11-11 09:55:17.542399: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
            "Numpy array shape (30522, 768)\n",
            "Loading bert/encoder/layer_0/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_0/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_0/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_0/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_0/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_0/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_0/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_0/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_1/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_1/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_1/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_1/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_1/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_1/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_1/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_1/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_10/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_10/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_10/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_10/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_10/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_10/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_10/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_10/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_11/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_11/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_11/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_11/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_11/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_11/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_11/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_11/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_2/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_2/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_2/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_2/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_2/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_2/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_2/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_2/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_3/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_3/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_3/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_3/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_3/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_3/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_3/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_3/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_4/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_4/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_4/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_4/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_4/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_4/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_4/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_4/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_5/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_5/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_5/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_5/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_5/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_5/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_5/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_5/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_6/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_6/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_6/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_6/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_6/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_6/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_6/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_6/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_7/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_7/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_7/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_7/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_7/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_7/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_7/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_7/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_8/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_8/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_8/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_8/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_8/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_8/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_8/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_8/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/encoder/layer_9/attention/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/output/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_9/attention/self/key/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/self/key/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_9/attention/self/query/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/self/query/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_9/attention/self/value/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/attention/self/value/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading bert/encoder/layer_9/intermediate/dense/bias with shape [3072]\n",
            "Numpy array shape (3072,)\n",
            "Loading bert/encoder/layer_9/intermediate/dense/kernel with shape [768, 3072]\n",
            "Numpy array shape (768, 3072)\n",
            "Loading bert/encoder/layer_9/output/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/output/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/output/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/encoder/layer_9/output/dense/kernel with shape [3072, 768]\n",
            "Numpy array shape (3072, 768)\n",
            "Loading bert/pooler/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading bert/pooler/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading cls/predictions/output_bias with shape [30522]\n",
            "Numpy array shape (30522,)\n",
            "Loading cls/predictions/transform/LayerNorm/beta with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading cls/predictions/transform/LayerNorm/gamma with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading cls/predictions/transform/dense/bias with shape [768]\n",
            "Numpy array shape (768,)\n",
            "Loading cls/predictions/transform/dense/kernel with shape [768, 768]\n",
            "Numpy array shape (768, 768)\n",
            "Loading cls/seq_relationship/output_bias with shape [2]\n",
            "Numpy array shape (2,)\n",
            "Loading cls/seq_relationship/output_weights with shape [2, 768]\n",
            "Numpy array shape (2, 768)\n",
            "Loading embeddings/LayerNorm/beta\n",
            "Loading embeddings/LayerNorm/gamma\n",
            "Loading embeddings/position_embeddings\n",
            "Loading embeddings/token_type_embeddings\n",
            "Loading embeddings/word_embeddings\n",
            "Loading encoder/layer_0/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_0/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_0/attention/output/dense/bias\n",
            "Loading encoder/layer_0/attention/output/dense/kernel\n",
            "Loading encoder/layer_0/attention/self/key/bias\n",
            "Loading encoder/layer_0/attention/self/key/kernel\n",
            "Loading encoder/layer_0/attention/self/query/bias\n",
            "Loading encoder/layer_0/attention/self/query/kernel\n",
            "Loading encoder/layer_0/attention/self/value/bias\n",
            "Loading encoder/layer_0/attention/self/value/kernel\n",
            "Loading encoder/layer_0/intermediate/dense/bias\n",
            "Loading encoder/layer_0/intermediate/dense/kernel\n",
            "Loading encoder/layer_0/output/LayerNorm/beta\n",
            "Loading encoder/layer_0/output/LayerNorm/gamma\n",
            "Loading encoder/layer_0/output/dense/bias\n",
            "Loading encoder/layer_0/output/dense/kernel\n",
            "Loading encoder/layer_1/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_1/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_1/attention/output/dense/bias\n",
            "Loading encoder/layer_1/attention/output/dense/kernel\n",
            "Loading encoder/layer_1/attention/self/key/bias\n",
            "Loading encoder/layer_1/attention/self/key/kernel\n",
            "Loading encoder/layer_1/attention/self/query/bias\n",
            "Loading encoder/layer_1/attention/self/query/kernel\n",
            "Loading encoder/layer_1/attention/self/value/bias\n",
            "Loading encoder/layer_1/attention/self/value/kernel\n",
            "Loading encoder/layer_1/intermediate/dense/bias\n",
            "Loading encoder/layer_1/intermediate/dense/kernel\n",
            "Loading encoder/layer_1/output/LayerNorm/beta\n",
            "Loading encoder/layer_1/output/LayerNorm/gamma\n",
            "Loading encoder/layer_1/output/dense/bias\n",
            "Loading encoder/layer_1/output/dense/kernel\n",
            "Loading encoder/layer_10/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_10/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_10/attention/output/dense/bias\n",
            "Loading encoder/layer_10/attention/output/dense/kernel\n",
            "Loading encoder/layer_10/attention/self/key/bias\n",
            "Loading encoder/layer_10/attention/self/key/kernel\n",
            "Loading encoder/layer_10/attention/self/query/bias\n",
            "Loading encoder/layer_10/attention/self/query/kernel\n",
            "Loading encoder/layer_10/attention/self/value/bias\n",
            "Loading encoder/layer_10/attention/self/value/kernel\n",
            "Loading encoder/layer_10/intermediate/dense/bias\n",
            "Loading encoder/layer_10/intermediate/dense/kernel\n",
            "Loading encoder/layer_10/output/LayerNorm/beta\n",
            "Loading encoder/layer_10/output/LayerNorm/gamma\n",
            "Loading encoder/layer_10/output/dense/bias\n",
            "Loading encoder/layer_10/output/dense/kernel\n",
            "Loading encoder/layer_11/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_11/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_11/attention/output/dense/bias\n",
            "Loading encoder/layer_11/attention/output/dense/kernel\n",
            "Loading encoder/layer_11/attention/self/key/bias\n",
            "Loading encoder/layer_11/attention/self/key/kernel\n",
            "Loading encoder/layer_11/attention/self/query/bias\n",
            "Loading encoder/layer_11/attention/self/query/kernel\n",
            "Loading encoder/layer_11/attention/self/value/bias\n",
            "Loading encoder/layer_11/attention/self/value/kernel\n",
            "Loading encoder/layer_11/intermediate/dense/bias\n",
            "Loading encoder/layer_11/intermediate/dense/kernel\n",
            "Loading encoder/layer_11/output/LayerNorm/beta\n",
            "Loading encoder/layer_11/output/LayerNorm/gamma\n",
            "Loading encoder/layer_11/output/dense/bias\n",
            "Loading encoder/layer_11/output/dense/kernel\n",
            "Loading encoder/layer_2/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_2/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_2/attention/output/dense/bias\n",
            "Loading encoder/layer_2/attention/output/dense/kernel\n",
            "Loading encoder/layer_2/attention/self/key/bias\n",
            "Loading encoder/layer_2/attention/self/key/kernel\n",
            "Loading encoder/layer_2/attention/self/query/bias\n",
            "Loading encoder/layer_2/attention/self/query/kernel\n",
            "Loading encoder/layer_2/attention/self/value/bias\n",
            "Loading encoder/layer_2/attention/self/value/kernel\n",
            "Loading encoder/layer_2/intermediate/dense/bias\n",
            "Loading encoder/layer_2/intermediate/dense/kernel\n",
            "Loading encoder/layer_2/output/LayerNorm/beta\n",
            "Loading encoder/layer_2/output/LayerNorm/gamma\n",
            "Loading encoder/layer_2/output/dense/bias\n",
            "Loading encoder/layer_2/output/dense/kernel\n",
            "Loading encoder/layer_3/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_3/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_3/attention/output/dense/bias\n",
            "Loading encoder/layer_3/attention/output/dense/kernel\n",
            "Loading encoder/layer_3/attention/self/key/bias\n",
            "Loading encoder/layer_3/attention/self/key/kernel\n",
            "Loading encoder/layer_3/attention/self/query/bias\n",
            "Loading encoder/layer_3/attention/self/query/kernel\n",
            "Loading encoder/layer_3/attention/self/value/bias\n",
            "Loading encoder/layer_3/attention/self/value/kernel\n",
            "Loading encoder/layer_3/intermediate/dense/bias\n",
            "Loading encoder/layer_3/intermediate/dense/kernel\n",
            "Loading encoder/layer_3/output/LayerNorm/beta\n",
            "Loading encoder/layer_3/output/LayerNorm/gamma\n",
            "Loading encoder/layer_3/output/dense/bias\n",
            "Loading encoder/layer_3/output/dense/kernel\n",
            "Loading encoder/layer_4/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_4/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_4/attention/output/dense/bias\n",
            "Loading encoder/layer_4/attention/output/dense/kernel\n",
            "Loading encoder/layer_4/attention/self/key/bias\n",
            "Loading encoder/layer_4/attention/self/key/kernel\n",
            "Loading encoder/layer_4/attention/self/query/bias\n",
            "Loading encoder/layer_4/attention/self/query/kernel\n",
            "Loading encoder/layer_4/attention/self/value/bias\n",
            "Loading encoder/layer_4/attention/self/value/kernel\n",
            "Loading encoder/layer_4/intermediate/dense/bias\n",
            "Loading encoder/layer_4/intermediate/dense/kernel\n",
            "Loading encoder/layer_4/output/LayerNorm/beta\n",
            "Loading encoder/layer_4/output/LayerNorm/gamma\n",
            "Loading encoder/layer_4/output/dense/bias\n",
            "Loading encoder/layer_4/output/dense/kernel\n",
            "Loading encoder/layer_5/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_5/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_5/attention/output/dense/bias\n",
            "Loading encoder/layer_5/attention/output/dense/kernel\n",
            "Loading encoder/layer_5/attention/self/key/bias\n",
            "Loading encoder/layer_5/attention/self/key/kernel\n",
            "Loading encoder/layer_5/attention/self/query/bias\n",
            "Loading encoder/layer_5/attention/self/query/kernel\n",
            "Loading encoder/layer_5/attention/self/value/bias\n",
            "Loading encoder/layer_5/attention/self/value/kernel\n",
            "Loading encoder/layer_5/intermediate/dense/bias\n",
            "Loading encoder/layer_5/intermediate/dense/kernel\n",
            "Loading encoder/layer_5/output/LayerNorm/beta\n",
            "Loading encoder/layer_5/output/LayerNorm/gamma\n",
            "Loading encoder/layer_5/output/dense/bias\n",
            "Loading encoder/layer_5/output/dense/kernel\n",
            "Loading encoder/layer_6/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_6/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_6/attention/output/dense/bias\n",
            "Loading encoder/layer_6/attention/output/dense/kernel\n",
            "Loading encoder/layer_6/attention/self/key/bias\n",
            "Loading encoder/layer_6/attention/self/key/kernel\n",
            "Loading encoder/layer_6/attention/self/query/bias\n",
            "Loading encoder/layer_6/attention/self/query/kernel\n",
            "Loading encoder/layer_6/attention/self/value/bias\n",
            "Loading encoder/layer_6/attention/self/value/kernel\n",
            "Loading encoder/layer_6/intermediate/dense/bias\n",
            "Loading encoder/layer_6/intermediate/dense/kernel\n",
            "Loading encoder/layer_6/output/LayerNorm/beta\n",
            "Loading encoder/layer_6/output/LayerNorm/gamma\n",
            "Loading encoder/layer_6/output/dense/bias\n",
            "Loading encoder/layer_6/output/dense/kernel\n",
            "Loading encoder/layer_7/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_7/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_7/attention/output/dense/bias\n",
            "Loading encoder/layer_7/attention/output/dense/kernel\n",
            "Loading encoder/layer_7/attention/self/key/bias\n",
            "Loading encoder/layer_7/attention/self/key/kernel\n",
            "Loading encoder/layer_7/attention/self/query/bias\n",
            "Loading encoder/layer_7/attention/self/query/kernel\n",
            "Loading encoder/layer_7/attention/self/value/bias\n",
            "Loading encoder/layer_7/attention/self/value/kernel\n",
            "Loading encoder/layer_7/intermediate/dense/bias\n",
            "Loading encoder/layer_7/intermediate/dense/kernel\n",
            "Loading encoder/layer_7/output/LayerNorm/beta\n",
            "Loading encoder/layer_7/output/LayerNorm/gamma\n",
            "Loading encoder/layer_7/output/dense/bias\n",
            "Loading encoder/layer_7/output/dense/kernel\n",
            "Loading encoder/layer_8/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_8/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_8/attention/output/dense/bias\n",
            "Loading encoder/layer_8/attention/output/dense/kernel\n",
            "Loading encoder/layer_8/attention/self/key/bias\n",
            "Loading encoder/layer_8/attention/self/key/kernel\n",
            "Loading encoder/layer_8/attention/self/query/bias\n",
            "Loading encoder/layer_8/attention/self/query/kernel\n",
            "Loading encoder/layer_8/attention/self/value/bias\n",
            "Loading encoder/layer_8/attention/self/value/kernel\n",
            "Loading encoder/layer_8/intermediate/dense/bias\n",
            "Loading encoder/layer_8/intermediate/dense/kernel\n",
            "Loading encoder/layer_8/output/LayerNorm/beta\n",
            "Loading encoder/layer_8/output/LayerNorm/gamma\n",
            "Loading encoder/layer_8/output/dense/bias\n",
            "Loading encoder/layer_8/output/dense/kernel\n",
            "Loading encoder/layer_9/attention/output/LayerNorm/beta\n",
            "Loading encoder/layer_9/attention/output/LayerNorm/gamma\n",
            "Loading encoder/layer_9/attention/output/dense/bias\n",
            "Loading encoder/layer_9/attention/output/dense/kernel\n",
            "Loading encoder/layer_9/attention/self/key/bias\n",
            "Loading encoder/layer_9/attention/self/key/kernel\n",
            "Loading encoder/layer_9/attention/self/query/bias\n",
            "Loading encoder/layer_9/attention/self/query/kernel\n",
            "Loading encoder/layer_9/attention/self/value/bias\n",
            "Loading encoder/layer_9/attention/self/value/kernel\n",
            "Loading encoder/layer_9/intermediate/dense/bias\n",
            "Loading encoder/layer_9/intermediate/dense/kernel\n",
            "Loading encoder/layer_9/output/LayerNorm/beta\n",
            "Loading encoder/layer_9/output/LayerNorm/gamma\n",
            "Loading encoder/layer_9/output/dense/bias\n",
            "Loading encoder/layer_9/output/dense/kernel\n",
            "Loading pooler/dense/bias\n",
            "Loading pooler/dense/kernel\n",
            "Loading redictions/output_bias\n",
            "Skipping\n",
            "Loading redictions/transform/LayerNorm/beta\n",
            "Skipping\n",
            "Loading redictions/transform/LayerNorm/gamma\n",
            "Skipping\n",
            "Loading redictions/transform/dense/bias\n",
            "Skipping\n",
            "Loading redictions/transform/dense/kernel\n",
            "Skipping\n",
            "Loading eq_relationship/output_bias\n",
            "Skipping\n",
            "Loading eq_relationship/output_weights\n",
            "Skipping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data pre-prep command\n",
        "# !cd TAS-BERT && cd data && python data_preprocessing_for_TAS.py --dataset semeval2015 && python data_preprocessing_for_TAS.py --dataset semeval2016"
      ],
      "metadata": {
        "id": "Dhjrym_jApHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data pre-prep with custom data\n",
        "import os\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('TAS-BERT/data/mock_data/', exist_ok=True)\n",
        "\n",
        "# Move the TSV files to the new directory\n",
        "os.rename('/content/df_mock_train.tsv', 'TAS-BERT/data/mock_data/df_mock_train.tsv')\n",
        "os.rename('/content/df_mock_test.tsv', 'TAS-BERT/data/mock_data/df_mock_test.tsv')\n",
        "\n",
        "print(\"TSV files moved successfully.\")"
      ],
      "metadata": {
        "id": "AuutywBGAx-0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6affc16e-41e2-40e7-942f-16d231c9e2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TSV files moved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modify the data_preprocessing code to take in mock_data as well.\n",
        "# in main, modify choices to take in mock_data\n",
        "# and on the next conditional, add in mock data file name for training and testing."
      ],
      "metadata": {
        "id": "Qf19jd-D1s6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-process custom data\n",
        "# Modify the data_preprocessing_for_TAS.py file to add 'mock_data' to the choices for the --dataset argument\n",
        "!sed -i \"s/choices={'semeval2015', 'semeval2016'}/choices={'semeval2015', 'seval2016', 'mock_data'}/\" TAS-BERT/data/data_preprocessing_for_TAS.py\n",
        "\n",
        "# Rename the .tsv files to .txt\n",
        "!mv TAS-BERT/data/mock_data/df_mock_train.tsv TAS-BERT/data/mock_data/df_mock_train.txt\n",
        "!mv TAS-BERT/data/mock_data/df_mock_test.tsv TAS-BERT/data/mock_data/df_mock_test.txt\n",
        "\n",
        "!cd TAS-BERT/data && python data_preprocessing_for_TAS.py --dataset mock_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT-7x25CKCVB",
        "outputId": "91d6f9a7-3368-4c76-ed5d-6fcbe11f3080",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entity_sum:  621\n",
            "max_sen_len:  120\n",
            "sample ratio:  620 - 15112\n",
            "entity_sum:  161\n",
            "max_sen_len:  134\n",
            "sample ratio:  161 - 3763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a9b4ee1",
        "outputId": "cf5215f7-45c8-4786-f516-4fb1aae8ec01"
      },
      "source": [
        "import os\n",
        "\n",
        "def trim_problematic_lines(filepath, expected_columns=5):\n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"File not found: {filepath}\")\n",
        "        return\n",
        "\n",
        "    temp_filepath = filepath + \".temp\"\n",
        "    problematic_count = 0\n",
        "    total_lines = 0\n",
        "\n",
        "    with open(filepath, 'r', encoding='utf-8') as infile, \\\n",
        "         open(temp_filepath, 'w', encoding='utf-8') as outfile:\n",
        "        for line_num, line in enumerate(infile, 1):\n",
        "            total_lines += 1\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                problematic_count += 1\n",
        "                continue\n",
        "\n",
        "            line_arr = line.split('\\t')\n",
        "            if len(line_arr) == expected_columns:\n",
        "                outfile.write(line + '\\n')\n",
        "            else:\n",
        "                problematic_count += 1\n",
        "\n",
        "    os.replace(temp_filepath, filepath)\n",
        "    print(f\"Trimmed {problematic_count} lines from {filepath}. Total lines processed: {total_lines}\")\n",
        "\n",
        "# Trim the training and testing TSV files\n",
        "trim_problematic_lines('/content/TAS-BERT/data/mock_data/three_joint/BIO/train_TAS.tsv')\n",
        "trim_problematic_lines('/content/TAS-BERT/data/mock_data/three_joint/BIO/test_TAS.tsv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trimmed 54 lines from /content/TAS-BERT/data/mock_data/three_joint/BIO/train_TAS.tsv. Total lines processed: 15733\n",
            "Trimmed 54 lines from /content/TAS-BERT/data/mock_data/three_joint/BIO/test_TAS.tsv. Total lines processed: 3925\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# command to train + test model\n",
        "!cd TAS-BERT && CUDA_VISIBLE_DEVICES=0 python TAS_BERT_joint.py \\\n",
        "--data_dir data/mock_data/three_joint/BIO/ \\\n",
        "--output_dir results/mock_data/three_joint/BIO/my_result \\\n",
        "--vocab_file uncased_L-12_H-768_A-12/vocab.txt \\\n",
        "--bert_config_file uncased_L-12_H-768_A-12/bert_config.json \\\n",
        "--init_checkpoint uncased_L-12_H-768_A-12/pytorch_model.bin \\\n",
        "--tokenize_method word_split \\\n",
        "--use_crf \\\n",
        "--eval_test \\\n",
        "--do_lower_case \\\n",
        "--max_seq_length 128 \\\n",
        "--train_batch_size 24 \\\n",
        "--eval_batch_size 8 \\\n",
        "--learning_rate 2e-5 \\\n",
        "--num_train_epochs 1.0"
      ],
      "metadata": {
        "id": "thhPzYK6A009",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8cf7b7-5e7d-48ec-c12b-d82bed70773e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-11 09:57:16.658576: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1762855036.933503    3358 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1762855037.003169    3358 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1762855037.538403    3358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762855037.538458    3358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762855037.538466    3358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1762855037.538472    3358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-11 09:57:17.596399: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "11/11/2025 09:57:32 - INFO - __main__ -   device cuda n_gpu 1 distributed training False\n",
            "['[PAD]', '[CLS]', 'O', 'B', 'I']\n",
            "100% 15678/15678 [00:04<00:00, 3590.06it/s]\n",
            "11/11/2025 09:57:37 - INFO - __main__ -   ***** Running training *****\n",
            "11/11/2025 09:57:37 - INFO - __main__ -     Num examples = 15678\n",
            "11/11/2025 09:57:37 - INFO - __main__ -     Batch size = 24\n",
            "11/11/2025 09:57:37 - INFO - __main__ -     Num steps = 653\n",
            "100% 3870/3870 [00:01<00:00, 3358.01it/s]\n",
            "output_log_file= results/mock_data/three_joint/BIO/my_result/log.txt\n",
            "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/654 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.12/dist-packages/torchcrf/__init__.py:249: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at /pytorch/aten/src/ATen/native/TensorCompare.cpp:615.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n",
            "/content/TAS-BERT/optimization.py:146: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1691.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n",
            "\n",
            "Iteration:   0% 1/654 [00:02<29:44,  2.73s/it]\u001b[A\n",
            "Iteration:   0% 2/654 [00:03<18:32,  1.71s/it]\u001b[A\n",
            "Iteration:   0% 3/654 [00:04<15:00,  1.38s/it]\u001b[A\n",
            "Iteration:   1% 4/654 [00:05<13:19,  1.23s/it]\u001b[A\n",
            "Iteration:   1% 5/654 [00:06<12:31,  1.16s/it]\u001b[A\n",
            "Iteration:   1% 6/654 [00:07<11:53,  1.10s/it]\u001b[A\n",
            "Iteration:   1% 7/654 [00:08<11:33,  1.07s/it]\u001b[A\n",
            "Iteration:   1% 8/654 [00:09<11:22,  1.06s/it]\u001b[A\n",
            "Iteration:   1% 9/654 [00:10<11:12,  1.04s/it]\u001b[A\n",
            "Iteration:   2% 10/654 [00:11<11:10,  1.04s/it]\u001b[A\n",
            "Iteration:   2% 11/654 [00:12<11:20,  1.06s/it]\u001b[A\n",
            "Iteration:   2% 12/654 [00:14<11:26,  1.07s/it]\u001b[A\n",
            "Iteration:   2% 13/654 [00:15<11:33,  1.08s/it]\u001b[A\n",
            "Iteration:   2% 14/654 [00:16<11:28,  1.08s/it]\u001b[A\n",
            "Iteration:   2% 15/654 [00:17<11:52,  1.11s/it]\u001b[A\n",
            "Iteration:   2% 16/654 [00:18<12:45,  1.20s/it]\u001b[A\n",
            "Iteration:   3% 17/654 [00:19<12:24,  1.17s/it]\u001b[A\n",
            "Iteration:   3% 18/654 [00:20<12:06,  1.14s/it]\u001b[A\n",
            "Iteration:   3% 19/654 [00:22<11:51,  1.12s/it]\u001b[A\n",
            "Iteration:   3% 20/654 [00:23<11:38,  1.10s/it]\u001b[A\n",
            "Iteration:   3% 21/654 [00:24<11:32,  1.09s/it]\u001b[A\n",
            "Iteration:   3% 22/654 [00:25<11:27,  1.09s/it]\u001b[A\n",
            "Iteration:   4% 23/654 [00:26<11:30,  1.09s/it]\u001b[A\n",
            "Iteration:   4% 24/654 [00:27<11:27,  1.09s/it]\u001b[A\n",
            "Iteration:   4% 25/654 [00:28<11:21,  1.08s/it]\u001b[A\n",
            "Iteration:   4% 26/654 [00:29<11:20,  1.08s/it]\u001b[A\n",
            "Iteration:   4% 27/654 [00:30<11:23,  1.09s/it]\u001b[A\n",
            "Iteration:   4% 28/654 [00:31<11:23,  1.09s/it]\u001b[A\n",
            "Iteration:   4% 29/654 [00:32<11:20,  1.09s/it]\u001b[A\n",
            "Iteration:   5% 30/654 [00:33<11:19,  1.09s/it]\u001b[A\n",
            "Iteration:   5% 31/654 [00:35<11:18,  1.09s/it]\u001b[A\n",
            "Iteration:   5% 32/654 [00:36<11:19,  1.09s/it]\u001b[A\n",
            "Iteration:   5% 33/654 [00:37<11:20,  1.10s/it]\u001b[A\n",
            "Iteration:   5% 34/654 [00:38<11:22,  1.10s/it]\u001b[A\n",
            "Iteration:   5% 35/654 [00:39<11:19,  1.10s/it]\u001b[A\n",
            "Iteration:   6% 36/654 [00:40<11:17,  1.10s/it]\u001b[A\n",
            "Iteration:   6% 37/654 [00:41<11:16,  1.10s/it]\u001b[A\n",
            "Iteration:   6% 38/654 [00:42<11:15,  1.10s/it]\u001b[A\n",
            "Iteration:   6% 39/654 [00:43<11:15,  1.10s/it]\u001b[A\n",
            "Iteration:   6% 40/654 [00:44<11:15,  1.10s/it]\u001b[A\n",
            "Iteration:   6% 41/654 [00:46<11:14,  1.10s/it]\u001b[A\n",
            "Iteration:   6% 42/654 [00:47<11:13,  1.10s/it]\u001b[A\n",
            "Iteration:   7% 43/654 [00:48<11:13,  1.10s/it]\u001b[A\n",
            "Iteration:   7% 44/654 [00:49<11:09,  1.10s/it]\u001b[A\n",
            "Iteration:   7% 45/654 [00:50<11:08,  1.10s/it]\u001b[A\n",
            "Iteration:   7% 46/654 [00:51<11:06,  1.10s/it]\u001b[A\n",
            "Iteration:   7% 47/654 [00:52<11:05,  1.10s/it]\u001b[A\n",
            "Iteration:   7% 48/654 [00:53<10:55,  1.08s/it]\u001b[A\n",
            "Iteration:   7% 49/654 [00:54<10:47,  1.07s/it]\u001b[A\n",
            "Iteration:   8% 50/654 [00:55<10:43,  1.06s/it]\u001b[A\n",
            "Iteration:   8% 51/654 [00:56<10:37,  1.06s/it]\u001b[A\n",
            "Iteration:   8% 52/654 [00:57<10:33,  1.05s/it]\u001b[A\n",
            "Iteration:   8% 53/654 [00:58<10:31,  1.05s/it]\u001b[A\n",
            "Iteration:   8% 54/654 [00:59<10:28,  1.05s/it]\u001b[A\n",
            "Iteration:   8% 55/654 [01:00<10:26,  1.05s/it]\u001b[A\n",
            "Iteration:   9% 56/654 [01:02<10:25,  1.05s/it]\u001b[A\n",
            "Iteration:   9% 57/654 [01:03<10:38,  1.07s/it]\u001b[A\n",
            "Iteration:   9% 58/654 [01:04<10:44,  1.08s/it]\u001b[A\n",
            "Iteration:   9% 59/654 [01:05<10:55,  1.10s/it]\u001b[A\n",
            "Iteration:   9% 60/654 [01:06<10:54,  1.10s/it]\u001b[A\n",
            "Iteration:   9% 61/654 [01:07<10:52,  1.10s/it]\u001b[A\n",
            "Iteration:   9% 62/654 [01:08<10:50,  1.10s/it]\u001b[A\n",
            "Iteration:  10% 63/654 [01:09<10:49,  1.10s/it]\u001b[A\n",
            "Iteration:  10% 64/654 [01:10<10:54,  1.11s/it]\u001b[A\n",
            "Iteration:  10% 65/654 [01:12<11:02,  1.13s/it]\u001b[A\n",
            "Iteration:  10% 66/654 [01:13<10:59,  1.12s/it]\u001b[A\n",
            "Iteration:  10% 67/654 [01:14<10:56,  1.12s/it]\u001b[A\n",
            "Iteration:  10% 68/654 [01:15<10:57,  1.12s/it]\u001b[A\n",
            "Iteration:  11% 69/654 [01:16<11:04,  1.14s/it]\u001b[A\n",
            "Iteration:  11% 70/654 [01:17<11:02,  1.13s/it]\u001b[A\n",
            "Iteration:  11% 71/654 [01:18<11:04,  1.14s/it]\u001b[A\n",
            "Iteration:  11% 72/654 [01:20<11:00,  1.14s/it]\u001b[A\n",
            "Iteration:  11% 73/654 [01:21<10:59,  1.14s/it]\u001b[A\n",
            "Iteration:  11% 74/654 [01:22<10:54,  1.13s/it]\u001b[A\n",
            "Iteration:  11% 75/654 [01:23<10:52,  1.13s/it]\u001b[A\n",
            "Iteration:  12% 76/654 [01:24<10:55,  1.13s/it]\u001b[A\n",
            "Iteration:  12% 77/654 [01:25<10:55,  1.14s/it]\u001b[A\n",
            "Iteration:  12% 78/654 [01:26<10:56,  1.14s/it]\u001b[A\n",
            "Iteration:  12% 79/654 [01:27<10:55,  1.14s/it]\u001b[A\n",
            "Iteration:  12% 80/654 [01:29<10:55,  1.14s/it]\u001b[A\n",
            "Iteration:  12% 81/654 [01:30<11:01,  1.15s/it]\u001b[A\n",
            "Iteration:  13% 82/654 [01:31<11:01,  1.16s/it]\u001b[A\n",
            "Iteration:  13% 83/654 [01:32<10:57,  1.15s/it]\u001b[A\n",
            "Iteration:  13% 84/654 [01:33<11:00,  1.16s/it]\u001b[A\n",
            "Iteration:  13% 85/654 [01:34<10:56,  1.15s/it]\u001b[A\n",
            "Iteration:  13% 86/654 [01:36<10:57,  1.16s/it]\u001b[A\n",
            "Iteration:  13% 87/654 [01:37<10:54,  1.15s/it]\u001b[A\n",
            "Iteration:  13% 88/654 [01:38<10:51,  1.15s/it]\u001b[A\n",
            "Iteration:  14% 89/654 [01:39<10:52,  1.15s/it]\u001b[A\n",
            "Iteration:  14% 90/654 [01:40<10:55,  1.16s/it]\u001b[A\n",
            "Iteration:  14% 91/654 [01:41<10:45,  1.15s/it]\u001b[A\n",
            "Iteration:  14% 92/654 [01:42<10:35,  1.13s/it]\u001b[A\n",
            "Iteration:  14% 93/654 [01:44<10:26,  1.12s/it]\u001b[A\n",
            "Iteration:  14% 94/654 [01:45<10:18,  1.10s/it]\u001b[A\n",
            "Iteration:  15% 95/654 [01:46<10:15,  1.10s/it]\u001b[A\n",
            "Iteration:  15% 96/654 [01:47<10:10,  1.09s/it]\u001b[A\n",
            "Iteration:  15% 97/654 [01:48<10:06,  1.09s/it]\u001b[A\n",
            "Iteration:  15% 98/654 [01:49<10:04,  1.09s/it]\u001b[A\n",
            "Iteration:  15% 99/654 [01:50<10:00,  1.08s/it]\u001b[A\n",
            "Iteration:  15% 100/654 [01:51<10:10,  1.10s/it]\u001b[A\n",
            "Iteration:  15% 101/654 [01:52<10:13,  1.11s/it]\u001b[A\n",
            "Iteration:  16% 102/654 [01:53<10:17,  1.12s/it]\u001b[A\n",
            "Iteration:  16% 103/654 [01:55<10:22,  1.13s/it]\u001b[A\n",
            "Iteration:  16% 104/654 [01:56<10:19,  1.13s/it]\u001b[A\n",
            "Iteration:  16% 105/654 [01:57<10:17,  1.13s/it]\u001b[A\n",
            "Iteration:  16% 106/654 [01:58<10:18,  1.13s/it]\u001b[A\n",
            "Iteration:  16% 107/654 [01:59<10:23,  1.14s/it]\u001b[A\n",
            "Iteration:  17% 108/654 [02:00<10:24,  1.14s/it]\u001b[A\n",
            "Iteration:  17% 109/654 [02:01<10:22,  1.14s/it]\u001b[A\n",
            "Iteration:  17% 110/654 [02:03<10:18,  1.14s/it]\u001b[A\n",
            "Iteration:  17% 111/654 [02:04<10:13,  1.13s/it]\u001b[A\n",
            "Iteration:  17% 112/654 [02:05<10:17,  1.14s/it]\u001b[A\n",
            "Iteration:  17% 113/654 [02:06<10:11,  1.13s/it]\u001b[A\n",
            "Iteration:  17% 114/654 [02:07<10:06,  1.12s/it]\u001b[A\n",
            "Iteration:  18% 115/654 [02:08<10:10,  1.13s/it]\u001b[A\n",
            "Iteration:  18% 116/654 [02:09<10:13,  1.14s/it]\u001b[A\n",
            "Iteration:  18% 117/654 [02:10<09:59,  1.12s/it]\u001b[A\n",
            "Iteration:  18% 118/654 [02:11<09:52,  1.11s/it]\u001b[A\n",
            "Iteration:  18% 119/654 [02:13<09:45,  1.09s/it]\u001b[A\n",
            "Iteration:  18% 120/654 [02:14<09:37,  1.08s/it]\u001b[A\n",
            "Iteration:  19% 121/654 [02:15<09:33,  1.08s/it]\u001b[A\n",
            "Iteration:  19% 122/654 [02:16<09:30,  1.07s/it]\u001b[A\n",
            "Iteration:  19% 123/654 [02:17<09:29,  1.07s/it]\u001b[A\n",
            "Iteration:  19% 124/654 [02:18<09:26,  1.07s/it]\u001b[A\n",
            "Iteration:  19% 125/654 [02:19<09:25,  1.07s/it]\u001b[A\n",
            "Iteration:  19% 126/654 [02:20<09:34,  1.09s/it]\u001b[A\n",
            "Iteration:  19% 127/654 [02:21<09:36,  1.09s/it]\u001b[A\n",
            "Iteration:  20% 128/654 [02:22<09:50,  1.12s/it]\u001b[A\n",
            "Iteration:  20% 129/654 [02:24<09:58,  1.14s/it]\u001b[A\n",
            "Iteration:  20% 130/654 [02:25<10:08,  1.16s/it]\u001b[A\n",
            "Iteration:  20% 131/654 [02:26<10:10,  1.17s/it]\u001b[A\n",
            "Iteration:  20% 132/654 [02:27<09:53,  1.14s/it]\u001b[A\n",
            "Iteration:  20% 133/654 [02:28<09:39,  1.11s/it]\u001b[A\n",
            "Iteration:  20% 134/654 [02:29<09:29,  1.10s/it]\u001b[A\n",
            "Iteration:  21% 135/654 [02:30<09:24,  1.09s/it]\u001b[A\n",
            "Iteration:  21% 136/654 [02:31<09:17,  1.08s/it]\u001b[A\n",
            "Iteration:  21% 137/654 [02:32<09:14,  1.07s/it]\u001b[A\n",
            "Iteration:  21% 138/654 [02:33<09:10,  1.07s/it]\u001b[A\n",
            "Iteration:  21% 139/654 [02:34<09:10,  1.07s/it]\u001b[A\n",
            "Iteration:  21% 140/654 [02:35<09:09,  1.07s/it]\u001b[A\n",
            "Iteration:  22% 141/654 [02:37<09:10,  1.07s/it]\u001b[A\n",
            "Iteration:  22% 142/654 [02:38<09:18,  1.09s/it]\u001b[A\n",
            "Iteration:  22% 143/654 [02:39<09:37,  1.13s/it]\u001b[A\n",
            "Iteration:  22% 144/654 [02:40<09:44,  1.15s/it]\u001b[A\n",
            "Iteration:  22% 145/654 [02:41<09:48,  1.16s/it]\u001b[A\n",
            "Iteration:  22% 146/654 [02:42<09:51,  1.17s/it]\u001b[A\n",
            "Iteration:  22% 147/654 [02:44<09:34,  1.13s/it]\u001b[A\n",
            "Iteration:  23% 148/654 [02:45<09:22,  1.11s/it]\u001b[A\n",
            "Iteration:  23% 149/654 [02:46<09:15,  1.10s/it]\u001b[A\n",
            "Iteration:  23% 150/654 [02:47<09:10,  1.09s/it]\u001b[A\n",
            "Iteration:  23% 151/654 [02:48<09:07,  1.09s/it]\u001b[A\n",
            "Iteration:  23% 152/654 [02:49<09:01,  1.08s/it]\u001b[A\n",
            "Iteration:  23% 153/654 [02:50<08:57,  1.07s/it]\u001b[A\n",
            "Iteration:  24% 154/654 [02:51<08:55,  1.07s/it]\u001b[A\n",
            "Iteration:  24% 155/654 [02:52<08:54,  1.07s/it]\u001b[A\n",
            "Iteration:  24% 156/654 [02:53<09:00,  1.09s/it]\u001b[A\n",
            "Iteration:  24% 157/654 [02:54<09:07,  1.10s/it]\u001b[A\n",
            "Iteration:  24% 158/654 [02:56<09:22,  1.13s/it]\u001b[A\n",
            "Iteration:  24% 159/654 [02:57<09:32,  1.16s/it]\u001b[A\n",
            "Iteration:  24% 160/654 [02:58<09:37,  1.17s/it]\u001b[A\n",
            "Iteration:  25% 161/654 [02:59<09:37,  1.17s/it]\u001b[A\n",
            "Iteration:  25% 162/654 [03:00<09:19,  1.14s/it]\u001b[A\n",
            "Iteration:  25% 163/654 [03:01<09:08,  1.12s/it]\u001b[A\n",
            "Iteration:  25% 164/654 [03:02<09:02,  1.11s/it]\u001b[A\n",
            "Iteration:  25% 165/654 [03:03<08:56,  1.10s/it]\u001b[A\n",
            "Iteration:  25% 166/654 [03:04<08:49,  1.08s/it]\u001b[A\n",
            "Iteration:  26% 167/654 [03:06<08:46,  1.08s/it]\u001b[A\n",
            "Iteration:  26% 168/654 [03:07<08:43,  1.08s/it]\u001b[A\n",
            "Iteration:  26% 169/654 [03:08<08:43,  1.08s/it]\u001b[A\n",
            "Iteration:  26% 170/654 [03:09<08:43,  1.08s/it]\u001b[A\n",
            "Iteration:  26% 171/654 [03:10<08:46,  1.09s/it]\u001b[A\n",
            "Iteration:  26% 172/654 [03:11<08:57,  1.11s/it]\u001b[A\n",
            "Iteration:  26% 173/654 [03:12<09:07,  1.14s/it]\u001b[A\n",
            "Iteration:  27% 174/654 [03:13<09:12,  1.15s/it]\u001b[A\n",
            "Iteration:  27% 175/654 [03:15<09:21,  1.17s/it]\u001b[A\n",
            "Iteration:  27% 176/654 [03:16<09:17,  1.17s/it]\u001b[A\n",
            "Iteration:  27% 177/654 [03:17<09:02,  1.14s/it]\u001b[A\n",
            "Iteration:  27% 178/654 [03:18<08:52,  1.12s/it]\u001b[A\n",
            "Iteration:  27% 179/654 [03:19<08:43,  1.10s/it]\u001b[A\n",
            "Iteration:  28% 180/654 [03:20<08:36,  1.09s/it]\u001b[A\n",
            "Iteration:  28% 181/654 [03:21<08:33,  1.09s/it]\u001b[A\n",
            "Iteration:  28% 182/654 [03:22<08:30,  1.08s/it]\u001b[A\n",
            "Iteration:  28% 183/654 [03:23<08:26,  1.08s/it]\u001b[A\n",
            "Iteration:  28% 184/654 [03:24<08:24,  1.07s/it]\u001b[A\n",
            "Iteration:  28% 185/654 [03:25<08:23,  1.07s/it]\u001b[A\n",
            "Iteration:  28% 186/654 [03:27<08:33,  1.10s/it]\u001b[A\n",
            "Iteration:  29% 187/654 [03:28<08:41,  1.12s/it]\u001b[A\n",
            "Iteration:  29% 188/654 [03:29<08:49,  1.14s/it]\u001b[A\n",
            "Iteration:  29% 189/654 [03:30<08:56,  1.15s/it]\u001b[A\n",
            "Iteration:  29% 190/654 [03:31<09:01,  1.17s/it]\u001b[A\n",
            "Iteration:  29% 191/654 [03:32<08:53,  1.15s/it]\u001b[A\n",
            "Iteration:  29% 192/654 [03:34<08:42,  1.13s/it]\u001b[A\n",
            "Iteration:  30% 193/654 [03:35<08:34,  1.12s/it]\u001b[A\n",
            "Iteration:  30% 194/654 [03:36<08:26,  1.10s/it]\u001b[A\n",
            "Iteration:  30% 195/654 [03:37<08:19,  1.09s/it]\u001b[A\n",
            "Iteration:  30% 196/654 [03:38<08:15,  1.08s/it]\u001b[A\n",
            "Iteration:  30% 197/654 [03:39<08:13,  1.08s/it]\u001b[A\n",
            "Iteration:  30% 198/654 [03:40<08:10,  1.08s/it]\u001b[A\n",
            "Iteration:  30% 199/654 [03:41<08:08,  1.07s/it]\u001b[A\n",
            "Iteration:  31% 200/654 [03:42<08:12,  1.08s/it]\u001b[A\n",
            "Iteration:  31% 201/654 [03:43<08:17,  1.10s/it]\u001b[A\n",
            "Iteration:  31% 202/654 [03:44<08:26,  1.12s/it]\u001b[A\n",
            "Iteration:  31% 203/654 [03:46<08:38,  1.15s/it]\u001b[A\n",
            "Iteration:  31% 204/654 [03:47<08:42,  1.16s/it]\u001b[A\n",
            "Iteration:  31% 205/654 [03:48<08:44,  1.17s/it]\u001b[A\n",
            "Iteration:  31% 206/654 [03:49<08:30,  1.14s/it]\u001b[A\n",
            "Iteration:  32% 207/654 [03:50<08:20,  1.12s/it]\u001b[A\n",
            "Iteration:  32% 208/654 [03:51<08:12,  1.10s/it]\u001b[A\n",
            "Iteration:  32% 209/654 [03:52<08:05,  1.09s/it]\u001b[A\n",
            "Iteration:  32% 210/654 [03:53<08:01,  1.09s/it]\u001b[A\n",
            "Iteration:  32% 211/654 [03:54<07:59,  1.08s/it]\u001b[A\n",
            "Iteration:  32% 212/654 [03:56<07:57,  1.08s/it]\u001b[A\n",
            "Iteration:  33% 213/654 [03:57<07:54,  1.08s/it]\u001b[A\n",
            "Iteration:  33% 214/654 [03:58<07:52,  1.07s/it]\u001b[A\n",
            "Iteration:  33% 215/654 [03:59<07:55,  1.08s/it]\u001b[A\n",
            "Iteration:  33% 216/654 [04:00<07:59,  1.09s/it]\u001b[A\n",
            "Iteration:  33% 217/654 [04:01<08:12,  1.13s/it]\u001b[A\n",
            "Iteration:  33% 218/654 [04:02<08:18,  1.14s/it]\u001b[A\n",
            "Iteration:  33% 219/654 [04:03<08:23,  1.16s/it]\u001b[A\n",
            "Iteration:  34% 220/654 [04:05<08:22,  1.16s/it]\u001b[A\n",
            "Iteration:  34% 221/654 [04:06<08:09,  1.13s/it]\u001b[A\n",
            "Iteration:  34% 222/654 [04:07<08:00,  1.11s/it]\u001b[A\n",
            "Iteration:  34% 223/654 [04:08<07:52,  1.10s/it]\u001b[A\n",
            "Iteration:  34% 224/654 [04:09<07:46,  1.08s/it]\u001b[A\n",
            "Iteration:  34% 225/654 [04:10<07:43,  1.08s/it]\u001b[A\n",
            "Iteration:  35% 226/654 [04:11<07:39,  1.07s/it]\u001b[A\n",
            "Iteration:  35% 227/654 [04:12<07:38,  1.07s/it]\u001b[A\n",
            "Iteration:  35% 228/654 [04:13<07:37,  1.07s/it]\u001b[A\n",
            "Iteration:  35% 229/654 [04:14<07:35,  1.07s/it]\u001b[A\n",
            "Iteration:  35% 230/654 [04:15<07:37,  1.08s/it]\u001b[A\n",
            "Iteration:  35% 231/654 [04:16<07:50,  1.11s/it]\u001b[A\n",
            "Iteration:  35% 232/654 [04:18<08:00,  1.14s/it]\u001b[A\n",
            "Iteration:  36% 233/654 [04:19<08:05,  1.15s/it]\u001b[A\n",
            "Iteration:  36% 234/654 [04:20<08:09,  1.17s/it]\u001b[A\n",
            "Iteration:  36% 235/654 [04:21<08:08,  1.17s/it]\u001b[A\n",
            "Iteration:  36% 236/654 [04:22<07:54,  1.13s/it]\u001b[A\n",
            "Iteration:  36% 237/654 [04:23<07:44,  1.11s/it]\u001b[A\n",
            "Iteration:  36% 238/654 [04:24<07:37,  1.10s/it]\u001b[A\n",
            "Iteration:  37% 239/654 [04:25<07:33,  1.09s/it]\u001b[A\n",
            "Iteration:  37% 240/654 [04:27<07:29,  1.09s/it]\u001b[A\n",
            "Iteration:  37% 241/654 [04:28<07:25,  1.08s/it]\u001b[A\n",
            "Iteration:  37% 242/654 [04:29<07:22,  1.07s/it]\u001b[A\n",
            "Iteration:  37% 243/654 [04:30<07:20,  1.07s/it]\u001b[A\n",
            "Iteration:  37% 244/654 [04:31<07:18,  1.07s/it]\u001b[A\n",
            "Iteration:  37% 245/654 [04:32<07:24,  1.09s/it]\u001b[A\n",
            "Iteration:  38% 246/654 [04:33<07:34,  1.11s/it]\u001b[A\n",
            "Iteration:  38% 247/654 [04:34<07:46,  1.15s/it]\u001b[A\n",
            "Iteration:  38% 248/654 [04:36<07:52,  1.16s/it]\u001b[A\n",
            "Iteration:  38% 249/654 [04:37<07:57,  1.18s/it]\u001b[A\n",
            "Iteration:  38% 250/654 [04:38<07:47,  1.16s/it]\u001b[A\n",
            "Iteration:  38% 251/654 [04:39<07:35,  1.13s/it]\u001b[A\n",
            "Iteration:  39% 252/654 [04:40<07:26,  1.11s/it]\u001b[A\n",
            "Iteration:  39% 253/654 [04:41<07:20,  1.10s/it]\u001b[A\n",
            "Iteration:  39% 254/654 [04:42<07:16,  1.09s/it]\u001b[A\n",
            "Iteration:  39% 255/654 [04:43<07:11,  1.08s/it]\u001b[A\n",
            "Iteration:  39% 256/654 [04:44<07:08,  1.08s/it]\u001b[A\n",
            "Iteration:  39% 257/654 [04:45<07:06,  1.07s/it]\u001b[A\n",
            "Iteration:  39% 258/654 [04:46<07:05,  1.07s/it]\u001b[A\n",
            "Iteration:  40% 259/654 [04:48<07:07,  1.08s/it]\u001b[A\n",
            "Iteration:  40% 260/654 [04:49<07:13,  1.10s/it]\u001b[A\n",
            "Iteration:  40% 261/654 [04:50<07:21,  1.12s/it]\u001b[A\n",
            "Iteration:  40% 262/654 [04:51<07:28,  1.14s/it]\u001b[A\n",
            "Iteration:  40% 263/654 [04:52<07:33,  1.16s/it]\u001b[A\n",
            "Iteration:  40% 264/654 [04:53<07:35,  1.17s/it]\u001b[A\n",
            "Iteration:  41% 265/654 [04:54<07:20,  1.13s/it]\u001b[A\n",
            "Iteration:  41% 266/654 [04:56<07:11,  1.11s/it]\u001b[A\n",
            "Iteration:  41% 267/654 [04:57<07:07,  1.10s/it]\u001b[A\n",
            "Iteration:  41% 268/654 [04:58<07:00,  1.09s/it]\u001b[A\n",
            "Iteration:  41% 269/654 [04:59<06:57,  1.09s/it]\u001b[A\n",
            "Iteration:  41% 270/654 [05:00<06:54,  1.08s/it]\u001b[A\n",
            "Iteration:  41% 271/654 [05:01<06:52,  1.08s/it]\u001b[A\n",
            "Iteration:  42% 272/654 [05:02<06:49,  1.07s/it]\u001b[A\n",
            "Iteration:  42% 273/654 [05:03<06:47,  1.07s/it]\u001b[A\n",
            "Iteration:  42% 274/654 [05:04<06:50,  1.08s/it]\u001b[A\n",
            "Iteration:  42% 275/654 [05:05<06:57,  1.10s/it]\u001b[A\n",
            "Iteration:  42% 276/654 [05:06<07:06,  1.13s/it]\u001b[A\n",
            "Iteration:  42% 277/654 [05:08<07:12,  1.15s/it]\u001b[A\n",
            "Iteration:  43% 278/654 [05:09<07:16,  1.16s/it]\u001b[A\n",
            "Iteration:  43% 279/654 [05:10<07:13,  1.16s/it]\u001b[A\n",
            "Iteration:  43% 280/654 [05:11<07:00,  1.12s/it]\u001b[A\n",
            "Iteration:  43% 281/654 [05:12<06:51,  1.10s/it]\u001b[A\n",
            "Iteration:  43% 282/654 [05:13<06:47,  1.10s/it]\u001b[A\n",
            "Iteration:  43% 283/654 [05:14<06:42,  1.09s/it]\u001b[A\n",
            "Iteration:  43% 284/654 [05:15<06:41,  1.08s/it]\u001b[A\n",
            "Iteration:  44% 285/654 [05:16<06:39,  1.08s/it]\u001b[A\n",
            "Iteration:  44% 286/654 [05:17<06:36,  1.08s/it]\u001b[A\n",
            "Iteration:  44% 287/654 [05:19<06:33,  1.07s/it]\u001b[A\n",
            "Iteration:  44% 288/654 [05:20<06:33,  1.08s/it]\u001b[A\n",
            "Iteration:  44% 289/654 [05:21<06:42,  1.10s/it]\u001b[A\n",
            "Iteration:  44% 290/654 [05:22<06:48,  1.12s/it]\u001b[A\n",
            "Iteration:  44% 291/654 [05:23<06:54,  1.14s/it]\u001b[A\n",
            "Iteration:  45% 292/654 [05:24<06:58,  1.16s/it]\u001b[A\n",
            "Iteration:  45% 293/654 [05:26<07:01,  1.17s/it]\u001b[A\n",
            "Iteration:  45% 294/654 [05:27<06:53,  1.15s/it]\u001b[A\n",
            "Iteration:  45% 295/654 [05:28<06:42,  1.12s/it]\u001b[A\n",
            "Iteration:  45% 296/654 [05:29<06:35,  1.10s/it]\u001b[A\n",
            "Iteration:  45% 297/654 [05:30<06:31,  1.10s/it]\u001b[A\n",
            "Iteration:  46% 298/654 [05:31<06:26,  1.08s/it]\u001b[A\n",
            "Iteration:  46% 299/654 [05:32<06:23,  1.08s/it]\u001b[A\n",
            "Iteration:  46% 300/654 [05:33<06:20,  1.07s/it]\u001b[A\n",
            "Iteration:  46% 301/654 [05:34<06:17,  1.07s/it]\u001b[A\n",
            "Iteration:  46% 302/654 [05:35<06:15,  1.07s/it]\u001b[A\n",
            "Iteration:  46% 303/654 [05:36<06:20,  1.09s/it]\u001b[A\n",
            "Iteration:  46% 304/654 [05:37<06:23,  1.10s/it]\u001b[A\n",
            "Iteration:  47% 305/654 [05:39<06:32,  1.13s/it]\u001b[A\n",
            "Iteration:  47% 306/654 [05:40<06:40,  1.15s/it]\u001b[A\n",
            "Iteration:  47% 307/654 [05:41<06:43,  1.16s/it]\u001b[A\n",
            "Iteration:  47% 308/654 [05:42<06:45,  1.17s/it]\u001b[A\n",
            "Iteration:  47% 309/654 [05:43<06:34,  1.14s/it]\u001b[A\n",
            "Iteration:  47% 310/654 [05:44<06:24,  1.12s/it]\u001b[A\n",
            "Iteration:  48% 311/654 [05:45<06:18,  1.10s/it]\u001b[A\n",
            "Iteration:  48% 312/654 [05:46<06:14,  1.10s/it]\u001b[A\n",
            "Iteration:  48% 313/654 [05:48<06:10,  1.09s/it]\u001b[A\n",
            "Iteration:  48% 314/654 [05:49<06:06,  1.08s/it]\u001b[A\n",
            "Iteration:  48% 315/654 [05:50<06:03,  1.07s/it]\u001b[A\n",
            "Iteration:  48% 316/654 [05:51<06:02,  1.07s/it]\u001b[A\n",
            "Iteration:  48% 317/654 [05:52<06:00,  1.07s/it]\u001b[A\n",
            "Iteration:  49% 318/654 [05:53<06:02,  1.08s/it]\u001b[A\n",
            "Iteration:  49% 319/654 [05:54<06:05,  1.09s/it]\u001b[A\n",
            "Iteration:  49% 320/654 [05:55<06:15,  1.12s/it]\u001b[A\n",
            "Iteration:  49% 321/654 [05:56<06:20,  1.14s/it]\u001b[A\n",
            "Iteration:  49% 322/654 [05:58<06:23,  1.16s/it]\u001b[A\n",
            "Iteration:  49% 323/654 [05:59<06:26,  1.17s/it]\u001b[A\n",
            "Iteration:  50% 324/654 [06:00<06:13,  1.13s/it]\u001b[A\n",
            "Iteration:  50% 325/654 [06:01<06:06,  1.11s/it]\u001b[A\n",
            "Iteration:  50% 326/654 [06:02<06:00,  1.10s/it]\u001b[A\n",
            "Iteration:  50% 327/654 [06:03<05:55,  1.09s/it]\u001b[A\n",
            "Iteration:  50% 328/654 [06:04<05:52,  1.08s/it]\u001b[A\n",
            "Iteration:  50% 329/654 [06:05<05:50,  1.08s/it]\u001b[A\n",
            "Iteration:  50% 330/654 [06:06<05:47,  1.07s/it]\u001b[A\n",
            "Iteration:  51% 331/654 [06:07<05:45,  1.07s/it]\u001b[A\n",
            "Iteration:  51% 332/654 [06:08<05:43,  1.07s/it]\u001b[A\n",
            "Iteration:  51% 333/654 [06:09<05:47,  1.08s/it]\u001b[A\n",
            "Iteration:  51% 334/654 [06:11<05:53,  1.11s/it]\u001b[A\n",
            "Iteration:  51% 335/654 [06:12<06:04,  1.14s/it]\u001b[A\n",
            "Iteration:  51% 336/654 [06:13<06:08,  1.16s/it]\u001b[A\n",
            "Iteration:  52% 337/654 [06:14<06:10,  1.17s/it]\u001b[A\n",
            "Iteration:  52% 338/654 [06:15<06:09,  1.17s/it]\u001b[A\n",
            "Iteration:  52% 339/654 [06:16<05:57,  1.14s/it]\u001b[A\n",
            "Iteration:  52% 340/654 [06:17<05:49,  1.11s/it]\u001b[A\n",
            "Iteration:  52% 341/654 [06:19<05:44,  1.10s/it]\u001b[A\n",
            "Iteration:  52% 342/654 [06:20<05:41,  1.09s/it]\u001b[A\n",
            "Iteration:  52% 343/654 [06:21<05:38,  1.09s/it]\u001b[A\n",
            "Iteration:  53% 344/654 [06:22<05:35,  1.08s/it]\u001b[A\n",
            "Iteration:  53% 345/654 [06:23<05:32,  1.08s/it]\u001b[A\n",
            "Iteration:  53% 346/654 [06:24<05:30,  1.07s/it]\u001b[A\n",
            "Iteration:  53% 347/654 [06:25<05:29,  1.07s/it]\u001b[A\n",
            "Iteration:  53% 348/654 [06:26<05:33,  1.09s/it]\u001b[A\n",
            "Iteration:  53% 349/654 [06:27<05:37,  1.11s/it]\u001b[A\n",
            "Iteration:  54% 350/654 [06:28<05:44,  1.13s/it]\u001b[A\n",
            "Iteration:  54% 351/654 [06:30<05:49,  1.15s/it]\u001b[A\n",
            "Iteration:  54% 352/654 [06:31<05:51,  1.17s/it]\u001b[A\n",
            "Iteration:  54% 353/654 [06:32<05:45,  1.15s/it]\u001b[A\n",
            "Iteration:  54% 354/654 [06:33<05:37,  1.12s/it]\u001b[A\n",
            "Iteration:  54% 355/654 [06:34<05:30,  1.10s/it]\u001b[A\n",
            "Iteration:  54% 356/654 [06:35<05:26,  1.10s/it]\u001b[A\n",
            "Iteration:  55% 357/654 [06:36<05:24,  1.09s/it]\u001b[A\n",
            "Iteration:  55% 358/654 [06:37<05:22,  1.09s/it]\u001b[A\n",
            "Iteration:  55% 359/654 [06:38<05:19,  1.08s/it]\u001b[A\n",
            "Iteration:  55% 360/654 [06:39<05:16,  1.08s/it]\u001b[A\n",
            "Iteration:  55% 361/654 [06:41<05:14,  1.07s/it]\u001b[A\n",
            "Iteration:  55% 362/654 [06:42<05:17,  1.09s/it]\u001b[A\n",
            "Iteration:  56% 363/654 [06:43<05:19,  1.10s/it]\u001b[A\n",
            "Iteration:  56% 364/654 [06:44<05:27,  1.13s/it]\u001b[A\n",
            "Iteration:  56% 365/654 [06:45<05:32,  1.15s/it]\u001b[A\n",
            "Iteration:  56% 366/654 [06:46<05:36,  1.17s/it]\u001b[A\n",
            "Iteration:  56% 367/654 [06:48<05:37,  1.18s/it]\u001b[A\n",
            "Iteration:  56% 368/654 [06:49<05:30,  1.15s/it]\u001b[A\n",
            "Iteration:  56% 369/654 [06:50<05:21,  1.13s/it]\u001b[A\n",
            "Iteration:  57% 370/654 [06:51<05:15,  1.11s/it]\u001b[A\n",
            "Iteration:  57% 371/654 [06:52<05:10,  1.10s/it]\u001b[A\n",
            "Iteration:  57% 372/654 [06:53<05:06,  1.09s/it]\u001b[A\n",
            "Iteration:  57% 373/654 [06:54<05:05,  1.09s/it]\u001b[A\n",
            "Iteration:  57% 374/654 [06:55<05:02,  1.08s/it]\u001b[A\n",
            "Iteration:  57% 375/654 [06:56<05:01,  1.08s/it]\u001b[A\n",
            "Iteration:  57% 376/654 [06:57<05:01,  1.09s/it]\u001b[A\n",
            "Iteration:  58% 377/654 [06:58<05:05,  1.10s/it]\u001b[A\n",
            "Iteration:  58% 378/654 [07:00<05:08,  1.12s/it]\u001b[A\n",
            "Iteration:  58% 379/654 [07:01<05:14,  1.15s/it]\u001b[A\n",
            "Iteration:  58% 380/654 [07:02<05:18,  1.16s/it]\u001b[A\n",
            "Iteration:  58% 381/654 [07:03<05:20,  1.17s/it]\u001b[A\n",
            "Iteration:  58% 382/654 [07:04<05:18,  1.17s/it]\u001b[A\n",
            "Iteration:  59% 383/654 [07:05<05:08,  1.14s/it]\u001b[A\n",
            "Iteration:  59% 384/654 [07:06<05:00,  1.11s/it]\u001b[A\n",
            "Iteration:  59% 385/654 [07:08<04:55,  1.10s/it]\u001b[A\n",
            "Iteration:  59% 386/654 [07:09<04:51,  1.09s/it]\u001b[A\n",
            "Iteration:  59% 387/654 [07:10<04:49,  1.08s/it]\u001b[A\n",
            "Iteration:  59% 388/654 [07:11<04:46,  1.08s/it]\u001b[A\n",
            "Iteration:  59% 389/654 [07:12<04:44,  1.07s/it]\u001b[A\n",
            "Iteration:  60% 390/654 [07:13<04:42,  1.07s/it]\u001b[A\n",
            "Iteration:  60% 391/654 [07:14<04:41,  1.07s/it]\u001b[A\n",
            "Iteration:  60% 392/654 [07:15<04:47,  1.10s/it]\u001b[A\n",
            "Iteration:  60% 393/654 [07:16<04:51,  1.12s/it]\u001b[A\n",
            "Iteration:  60% 394/654 [07:17<04:57,  1.14s/it]\u001b[A\n",
            "Iteration:  60% 395/654 [07:19<05:00,  1.16s/it]\u001b[A\n",
            "Iteration:  61% 396/654 [07:20<05:01,  1.17s/it]\u001b[A\n",
            "Iteration:  61% 397/654 [07:21<04:55,  1.15s/it]\u001b[A\n",
            "Iteration:  61% 398/654 [07:22<04:47,  1.12s/it]\u001b[A\n",
            "Iteration:  61% 399/654 [07:23<04:42,  1.11s/it]\u001b[A\n",
            "Iteration:  61% 400/654 [07:24<04:38,  1.10s/it]\u001b[A\n",
            "Iteration:  61% 401/654 [07:25<04:37,  1.10s/it]\u001b[A\n",
            "Iteration:  61% 402/654 [07:26<04:34,  1.09s/it]\u001b[A\n",
            "Iteration:  62% 403/654 [07:27<04:32,  1.09s/it]\u001b[A\n",
            "Iteration:  62% 404/654 [07:28<04:29,  1.08s/it]\u001b[A\n",
            "Iteration:  62% 405/654 [07:30<04:27,  1.07s/it]\u001b[A\n",
            "Iteration:  62% 406/654 [07:31<04:28,  1.08s/it]\u001b[A\n",
            "Iteration:  62% 407/654 [07:32<04:29,  1.09s/it]\u001b[A\n",
            "Iteration:  62% 408/654 [07:33<04:33,  1.11s/it]\u001b[A\n",
            "Iteration:  63% 409/654 [07:34<04:38,  1.14s/it]\u001b[A\n",
            "Iteration:  63% 410/654 [07:35<04:43,  1.16s/it]\u001b[A\n",
            "Iteration:  63% 411/654 [07:37<04:45,  1.17s/it]\u001b[A\n",
            "Iteration:  63% 412/654 [07:38<04:36,  1.14s/it]\u001b[A\n",
            "Iteration:  63% 413/654 [07:39<04:29,  1.12s/it]\u001b[A\n",
            "Iteration:  63% 414/654 [07:40<04:24,  1.10s/it]\u001b[A\n",
            "Iteration:  63% 415/654 [07:41<04:20,  1.09s/it]\u001b[A\n",
            "Iteration:  64% 416/654 [07:42<04:18,  1.09s/it]\u001b[A\n",
            "Iteration:  64% 417/654 [07:43<04:15,  1.08s/it]\u001b[A\n",
            "Iteration:  64% 418/654 [07:44<04:13,  1.08s/it]\u001b[A\n",
            "Iteration:  64% 419/654 [07:45<04:12,  1.07s/it]\u001b[A\n",
            "Iteration:  64% 420/654 [07:46<04:10,  1.07s/it]\u001b[A\n",
            "Iteration:  64% 421/654 [07:47<04:12,  1.08s/it]\u001b[A\n",
            "Iteration:  65% 422/654 [07:48<04:14,  1.10s/it]\u001b[A\n",
            "Iteration:  65% 423/654 [07:50<04:18,  1.12s/it]\u001b[A\n",
            "Iteration:  65% 424/654 [07:51<04:22,  1.14s/it]\u001b[A\n",
            "Iteration:  65% 425/654 [07:52<04:23,  1.15s/it]\u001b[A\n",
            "Iteration:  65% 426/654 [07:53<04:25,  1.16s/it]\u001b[A\n",
            "Iteration:  65% 427/654 [07:54<04:18,  1.14s/it]\u001b[A\n",
            "Iteration:  65% 428/654 [07:55<04:12,  1.12s/it]\u001b[A\n",
            "Iteration:  66% 429/654 [07:56<04:07,  1.10s/it]\u001b[A\n",
            "Iteration:  66% 430/654 [07:57<04:04,  1.09s/it]\u001b[A\n",
            "Iteration:  66% 431/654 [07:58<04:01,  1.08s/it]\u001b[A\n",
            "Iteration:  66% 432/654 [08:00<04:00,  1.08s/it]\u001b[A\n",
            "Iteration:  66% 433/654 [08:01<03:58,  1.08s/it]\u001b[A\n",
            "Iteration:  66% 434/654 [08:02<03:56,  1.07s/it]\u001b[A\n",
            "Iteration:  67% 435/654 [08:03<03:54,  1.07s/it]\u001b[A\n",
            "Iteration:  67% 436/654 [08:04<03:55,  1.08s/it]\u001b[A\n",
            "Iteration:  67% 437/654 [08:05<03:59,  1.10s/it]\u001b[A\n",
            "Iteration:  67% 438/654 [08:06<04:04,  1.13s/it]\u001b[A\n",
            "Iteration:  67% 439/654 [08:07<04:08,  1.16s/it]\u001b[A\n",
            "Iteration:  67% 440/654 [08:09<04:11,  1.17s/it]\u001b[A\n",
            "Iteration:  67% 441/654 [08:10<04:09,  1.17s/it]\u001b[A\n",
            "Iteration:  68% 442/654 [08:11<04:01,  1.14s/it]\u001b[A\n",
            "Iteration:  68% 443/654 [08:12<03:55,  1.12s/it]\u001b[A\n",
            "Iteration:  68% 444/654 [08:13<03:51,  1.10s/it]\u001b[A\n",
            "Iteration:  68% 445/654 [08:14<03:48,  1.09s/it]\u001b[A\n",
            "Iteration:  68% 446/654 [08:15<03:47,  1.09s/it]\u001b[A\n",
            "Iteration:  68% 447/654 [08:16<03:45,  1.09s/it]\u001b[A\n",
            "Iteration:  69% 448/654 [08:17<03:43,  1.08s/it]\u001b[A\n",
            "Iteration:  69% 449/654 [08:18<03:41,  1.08s/it]\u001b[A\n",
            "Iteration:  69% 450/654 [08:19<03:39,  1.07s/it]\u001b[A\n",
            "Iteration:  69% 451/654 [08:21<03:40,  1.09s/it]\u001b[A\n",
            "Iteration:  69% 452/654 [08:22<03:44,  1.11s/it]\u001b[A\n",
            "Iteration:  69% 453/654 [08:23<03:47,  1.13s/it]\u001b[A\n",
            "Iteration:  69% 454/654 [08:24<03:49,  1.15s/it]\u001b[A\n",
            "Iteration:  70% 455/654 [08:25<03:51,  1.16s/it]\u001b[A\n",
            "Iteration:  70% 456/654 [08:26<03:48,  1.16s/it]\u001b[A\n",
            "Iteration:  70% 457/654 [08:27<03:41,  1.12s/it]\u001b[A\n",
            "Iteration:  70% 458/654 [08:28<03:37,  1.11s/it]\u001b[A\n",
            "Iteration:  70% 459/654 [08:30<03:33,  1.09s/it]\u001b[A\n",
            "Iteration:  70% 460/654 [08:31<03:30,  1.09s/it]\u001b[A\n",
            "Iteration:  70% 461/654 [08:32<03:28,  1.08s/it]\u001b[A\n",
            "Iteration:  71% 462/654 [08:33<03:26,  1.07s/it]\u001b[A\n",
            "Iteration:  71% 463/654 [08:34<03:24,  1.07s/it]\u001b[A\n",
            "Iteration:  71% 464/654 [08:35<03:22,  1.07s/it]\u001b[A\n",
            "Iteration:  71% 465/654 [08:36<03:20,  1.06s/it]\u001b[A\n",
            "Iteration:  71% 466/654 [08:37<03:23,  1.08s/it]\u001b[A\n",
            "Iteration:  71% 467/654 [08:38<03:28,  1.12s/it]\u001b[A\n",
            "Iteration:  72% 468/654 [08:39<03:32,  1.14s/it]\u001b[A\n",
            "Iteration:  72% 469/654 [08:41<03:34,  1.16s/it]\u001b[A\n",
            "Iteration:  72% 470/654 [08:42<03:35,  1.17s/it]\u001b[A\n",
            "Iteration:  72% 471/654 [08:43<03:30,  1.15s/it]\u001b[A\n",
            "Iteration:  72% 472/654 [08:44<03:24,  1.12s/it]\u001b[A\n",
            "Iteration:  72% 473/654 [08:45<03:20,  1.11s/it]\u001b[A\n",
            "Iteration:  72% 474/654 [08:46<03:17,  1.10s/it]\u001b[A\n",
            "Iteration:  73% 475/654 [08:47<03:14,  1.09s/it]\u001b[A\n",
            "Iteration:  73% 476/654 [08:48<03:13,  1.09s/it]\u001b[A\n",
            "Iteration:  73% 477/654 [08:49<03:11,  1.08s/it]\u001b[A\n",
            "Iteration:  73% 478/654 [08:50<03:09,  1.08s/it]\u001b[A\n",
            "Iteration:  73% 479/654 [08:52<03:08,  1.08s/it]\u001b[A\n",
            "Iteration:  73% 480/654 [08:53<03:07,  1.08s/it]\u001b[A\n",
            "Iteration:  74% 481/654 [08:54<03:10,  1.10s/it]\u001b[A\n",
            "Iteration:  74% 482/654 [08:55<03:13,  1.12s/it]\u001b[A\n",
            "Iteration:  74% 483/654 [08:56<03:14,  1.14s/it]\u001b[A\n",
            "Iteration:  74% 484/654 [08:57<03:16,  1.16s/it]\u001b[A\n",
            "Iteration:  74% 485/654 [08:58<03:16,  1.17s/it]\u001b[A\n",
            "Iteration:  74% 486/654 [09:00<03:10,  1.13s/it]\u001b[A\n",
            "Iteration:  74% 487/654 [09:01<03:05,  1.11s/it]\u001b[A\n",
            "Iteration:  75% 488/654 [09:02<03:02,  1.10s/it]\u001b[A\n",
            "Iteration:  75% 489/654 [09:03<02:59,  1.09s/it]\u001b[A\n",
            "Iteration:  75% 490/654 [09:04<02:57,  1.08s/it]\u001b[A\n",
            "Iteration:  75% 491/654 [09:05<02:55,  1.08s/it]\u001b[A\n",
            "Iteration:  75% 492/654 [09:06<02:53,  1.07s/it]\u001b[A\n",
            "Iteration:  75% 493/654 [09:07<02:52,  1.07s/it]\u001b[A\n",
            "Iteration:  76% 494/654 [09:08<02:50,  1.06s/it]\u001b[A\n",
            "Iteration:  76% 495/654 [09:09<02:52,  1.08s/it]\u001b[A\n",
            "Iteration:  76% 496/654 [09:10<02:53,  1.10s/it]\u001b[A\n",
            "Iteration:  76% 497/654 [09:12<02:57,  1.13s/it]\u001b[A\n",
            "Iteration:  76% 498/654 [09:13<02:59,  1.15s/it]\u001b[A\n",
            "Iteration:  76% 499/654 [09:14<03:00,  1.16s/it]\u001b[A\n",
            "Iteration:  76% 500/654 [09:15<02:58,  1.16s/it]\u001b[A\n",
            "Iteration:  77% 501/654 [09:16<02:53,  1.13s/it]\u001b[A\n",
            "Iteration:  77% 502/654 [09:17<02:49,  1.11s/it]\u001b[A\n",
            "Iteration:  77% 503/654 [09:18<02:46,  1.10s/it]\u001b[A\n",
            "Iteration:  77% 504/654 [09:19<02:45,  1.10s/it]\u001b[A\n",
            "Iteration:  77% 505/654 [09:20<02:42,  1.09s/it]\u001b[A\n",
            "Iteration:  77% 506/654 [09:21<02:39,  1.08s/it]\u001b[A\n",
            "Iteration:  78% 507/654 [09:23<02:38,  1.08s/it]\u001b[A\n",
            "Iteration:  78% 508/654 [09:24<02:37,  1.08s/it]\u001b[A\n",
            "Iteration:  78% 509/654 [09:25<02:36,  1.08s/it]\u001b[A\n",
            "Iteration:  78% 510/654 [09:26<02:38,  1.10s/it]\u001b[A\n",
            "Iteration:  78% 511/654 [09:27<02:39,  1.12s/it]\u001b[A\n",
            "Iteration:  78% 512/654 [09:28<02:41,  1.14s/it]\u001b[A\n",
            "Iteration:  78% 513/654 [09:29<02:43,  1.16s/it]\u001b[A\n",
            "Iteration:  79% 514/654 [09:31<02:44,  1.17s/it]\u001b[A\n",
            "Iteration:  79% 515/654 [09:32<02:42,  1.17s/it]\u001b[A\n",
            "Iteration:  79% 516/654 [09:33<02:36,  1.13s/it]\u001b[A\n",
            "Iteration:  79% 517/654 [09:34<02:32,  1.11s/it]\u001b[A\n",
            "Iteration:  79% 518/654 [09:35<02:29,  1.10s/it]\u001b[A\n",
            "Iteration:  79% 519/654 [09:36<02:26,  1.09s/it]\u001b[A\n",
            "Iteration:  80% 520/654 [09:37<02:25,  1.08s/it]\u001b[A\n",
            "Iteration:  80% 521/654 [09:38<02:23,  1.08s/it]\u001b[A\n",
            "Iteration:  80% 522/654 [09:39<02:21,  1.08s/it]\u001b[A\n",
            "Iteration:  80% 523/654 [09:40<02:21,  1.08s/it]\u001b[A\n",
            "Iteration:  80% 524/654 [09:41<02:21,  1.09s/it]\u001b[A\n",
            "Iteration:  80% 525/654 [09:43<02:21,  1.10s/it]\u001b[A\n",
            "Iteration:  80% 526/654 [09:44<02:25,  1.13s/it]\u001b[A\n",
            "Iteration:  81% 527/654 [09:45<02:26,  1.16s/it]\u001b[A\n",
            "Iteration:  81% 528/654 [09:46<02:26,  1.17s/it]\u001b[A\n",
            "Iteration:  81% 529/654 [09:47<02:26,  1.18s/it]\u001b[A\n",
            "Iteration:  81% 530/654 [09:48<02:22,  1.15s/it]\u001b[A\n",
            "Iteration:  81% 531/654 [09:50<02:18,  1.13s/it]\u001b[A\n",
            "Iteration:  81% 532/654 [09:51<02:15,  1.11s/it]\u001b[A\n",
            "Iteration:  81% 533/654 [09:52<02:12,  1.10s/it]\u001b[A\n",
            "Iteration:  82% 534/654 [09:53<02:10,  1.09s/it]\u001b[A\n",
            "Iteration:  82% 535/654 [09:54<02:08,  1.08s/it]\u001b[A\n",
            "Iteration:  82% 536/654 [09:55<02:06,  1.08s/it]\u001b[A\n",
            "Iteration:  82% 537/654 [09:56<02:05,  1.07s/it]\u001b[A\n",
            "Iteration:  82% 538/654 [09:57<02:04,  1.07s/it]\u001b[A\n",
            "Iteration:  82% 539/654 [09:58<02:05,  1.09s/it]\u001b[A\n",
            "Iteration:  83% 540/654 [09:59<02:05,  1.10s/it]\u001b[A\n",
            "Iteration:  83% 541/654 [10:00<02:08,  1.14s/it]\u001b[A\n",
            "Iteration:  83% 542/654 [10:02<02:09,  1.16s/it]\u001b[A\n",
            "Iteration:  83% 543/654 [10:03<02:09,  1.17s/it]\u001b[A\n",
            "Iteration:  83% 544/654 [10:04<02:09,  1.18s/it]\u001b[A\n",
            "Iteration:  83% 545/654 [10:05<02:04,  1.14s/it]\u001b[A\n",
            "Iteration:  83% 546/654 [10:06<02:00,  1.12s/it]\u001b[A\n",
            "Iteration:  84% 547/654 [10:07<01:57,  1.10s/it]\u001b[A\n",
            "Iteration:  84% 548/654 [10:08<01:55,  1.09s/it]\u001b[A\n",
            "Iteration:  84% 549/654 [10:09<01:54,  1.09s/it]\u001b[A\n",
            "Iteration:  84% 550/654 [10:11<01:53,  1.09s/it]\u001b[A\n",
            "Iteration:  84% 551/654 [10:12<01:50,  1.08s/it]\u001b[A\n",
            "Iteration:  84% 552/654 [10:13<01:49,  1.07s/it]\u001b[A\n",
            "Iteration:  85% 553/654 [10:14<01:48,  1.07s/it]\u001b[A\n",
            "Iteration:  85% 554/654 [10:15<01:48,  1.08s/it]\u001b[A\n",
            "Iteration:  85% 555/654 [10:16<01:49,  1.10s/it]\u001b[A\n",
            "Iteration:  85% 556/654 [10:17<01:50,  1.13s/it]\u001b[A\n",
            "Iteration:  85% 557/654 [10:18<01:51,  1.15s/it]\u001b[A\n",
            "Iteration:  85% 558/654 [10:20<01:51,  1.16s/it]\u001b[A\n",
            "Iteration:  85% 559/654 [10:21<01:50,  1.16s/it]\u001b[A\n",
            "Iteration:  86% 560/654 [10:22<01:46,  1.13s/it]\u001b[A\n",
            "Iteration:  86% 561/654 [10:23<01:43,  1.11s/it]\u001b[A\n",
            "Iteration:  86% 562/654 [10:24<01:41,  1.10s/it]\u001b[A\n",
            "Iteration:  86% 563/654 [10:25<01:39,  1.09s/it]\u001b[A\n",
            "Iteration:  86% 564/654 [10:26<01:37,  1.08s/it]\u001b[A\n",
            "Iteration:  86% 565/654 [10:27<01:35,  1.08s/it]\u001b[A\n",
            "Iteration:  87% 566/654 [10:28<01:34,  1.08s/it]\u001b[A\n",
            "Iteration:  87% 567/654 [10:29<01:33,  1.07s/it]\u001b[A\n",
            "Iteration:  87% 568/654 [10:30<01:32,  1.07s/it]\u001b[A\n",
            "Iteration:  87% 569/654 [10:31<01:32,  1.09s/it]\u001b[A\n",
            "Iteration:  87% 570/654 [10:33<01:34,  1.12s/it]\u001b[A\n",
            "Iteration:  87% 571/654 [10:34<01:34,  1.14s/it]\u001b[A\n",
            "Iteration:  87% 572/654 [10:35<01:34,  1.16s/it]\u001b[A\n",
            "Iteration:  88% 573/654 [10:36<01:34,  1.17s/it]\u001b[A\n",
            "Iteration:  88% 574/654 [10:37<01:32,  1.16s/it]\u001b[A\n",
            "Iteration:  88% 575/654 [10:38<01:29,  1.13s/it]\u001b[A\n",
            "Iteration:  88% 576/654 [10:39<01:26,  1.11s/it]\u001b[A\n",
            "Iteration:  88% 577/654 [10:41<01:24,  1.10s/it]\u001b[A\n",
            "Iteration:  88% 578/654 [10:42<01:22,  1.09s/it]\u001b[A\n",
            "Iteration:  89% 579/654 [10:43<01:21,  1.09s/it]\u001b[A\n",
            "Iteration:  89% 580/654 [10:44<01:19,  1.08s/it]\u001b[A\n",
            "Iteration:  89% 581/654 [10:45<01:18,  1.08s/it]\u001b[A\n",
            "Iteration:  89% 582/654 [10:46<01:17,  1.07s/it]\u001b[A\n",
            "Iteration:  89% 583/654 [10:47<01:16,  1.08s/it]\u001b[A\n",
            "Iteration:  89% 584/654 [10:48<01:16,  1.10s/it]\u001b[A\n",
            "Iteration:  89% 585/654 [10:49<01:17,  1.12s/it]\u001b[A\n",
            "Iteration:  90% 586/654 [10:50<01:17,  1.14s/it]\u001b[A\n",
            "Iteration:  90% 587/654 [10:52<01:17,  1.16s/it]\u001b[A\n",
            "Iteration:  90% 588/654 [10:53<01:16,  1.16s/it]\u001b[A\n",
            "Iteration:  90% 589/654 [10:54<01:13,  1.14s/it]\u001b[A\n",
            "Iteration:  90% 590/654 [10:55<01:11,  1.12s/it]\u001b[A\n",
            "Iteration:  90% 591/654 [10:56<01:09,  1.11s/it]\u001b[A\n",
            "Iteration:  91% 592/654 [10:57<01:08,  1.10s/it]\u001b[A\n",
            "Iteration:  91% 593/654 [10:58<01:06,  1.09s/it]\u001b[A\n",
            "Iteration:  91% 594/654 [10:59<01:04,  1.08s/it]\u001b[A\n",
            "Iteration:  91% 595/654 [11:00<01:03,  1.08s/it]\u001b[A\n",
            "Iteration:  91% 596/654 [11:01<01:02,  1.08s/it]\u001b[A\n",
            "Iteration:  91% 597/654 [11:03<01:01,  1.08s/it]\u001b[A\n",
            "Iteration:  91% 598/654 [11:04<01:01,  1.09s/it]\u001b[A\n",
            "Iteration:  92% 599/654 [11:05<01:00,  1.10s/it]\u001b[A\n",
            "Iteration:  92% 600/654 [11:06<01:00,  1.12s/it]\u001b[A\n",
            "Iteration:  92% 601/654 [11:07<01:00,  1.14s/it]\u001b[A\n",
            "Iteration:  92% 602/654 [11:08<01:00,  1.16s/it]\u001b[A\n",
            "Iteration:  92% 603/654 [11:09<00:58,  1.15s/it]\u001b[A\n",
            "Iteration:  92% 604/654 [11:11<00:56,  1.12s/it]\u001b[A\n",
            "Iteration:  93% 605/654 [11:12<00:54,  1.11s/it]\u001b[A\n",
            "Iteration:  93% 606/654 [11:13<00:52,  1.10s/it]\u001b[A\n",
            "Iteration:  93% 607/654 [11:14<00:51,  1.09s/it]\u001b[A\n",
            "Iteration:  93% 608/654 [11:15<00:49,  1.08s/it]\u001b[A\n",
            "Iteration:  93% 609/654 [11:16<00:48,  1.08s/it]\u001b[A\n",
            "Iteration:  93% 610/654 [11:17<00:47,  1.08s/it]\u001b[A\n",
            "Iteration:  93% 611/654 [11:18<00:46,  1.08s/it]\u001b[A\n",
            "Iteration:  94% 612/654 [11:19<00:45,  1.08s/it]\u001b[A\n",
            "Iteration:  94% 613/654 [11:20<00:44,  1.09s/it]\u001b[A\n",
            "Iteration:  94% 614/654 [11:21<00:44,  1.11s/it]\u001b[A\n",
            "Iteration:  94% 615/654 [11:23<00:44,  1.14s/it]\u001b[A\n",
            "Iteration:  94% 616/654 [11:24<00:43,  1.15s/it]\u001b[A\n",
            "Iteration:  94% 617/654 [11:25<00:43,  1.16s/it]\u001b[A\n",
            "Iteration:  94% 618/654 [11:26<00:41,  1.16s/it]\u001b[A\n",
            "Iteration:  95% 619/654 [11:27<00:39,  1.14s/it]\u001b[A\n",
            "Iteration:  95% 620/654 [11:28<00:37,  1.11s/it]\u001b[A\n",
            "Iteration:  95% 621/654 [11:29<00:36,  1.10s/it]\u001b[A\n",
            "Iteration:  95% 622/654 [11:30<00:35,  1.09s/it]\u001b[A\n",
            "Iteration:  95% 623/654 [11:31<00:33,  1.09s/it]\u001b[A\n",
            "Iteration:  95% 624/654 [11:33<00:32,  1.08s/it]\u001b[A\n",
            "Iteration:  96% 625/654 [11:34<00:31,  1.07s/it]\u001b[A\n",
            "Iteration:  96% 626/654 [11:35<00:30,  1.07s/it]\u001b[A\n",
            "Iteration:  96% 627/654 [11:36<00:29,  1.08s/it]\u001b[A\n",
            "Iteration:  96% 628/654 [11:37<00:28,  1.10s/it]\u001b[A\n",
            "Iteration:  96% 629/654 [11:38<00:28,  1.12s/it]\u001b[A\n",
            "Iteration:  96% 630/654 [11:39<00:27,  1.15s/it]\u001b[A\n",
            "Iteration:  96% 631/654 [11:40<00:26,  1.16s/it]\u001b[A\n",
            "Iteration:  97% 632/654 [11:42<00:25,  1.17s/it]\u001b[A\n",
            "Iteration:  97% 633/654 [11:43<00:24,  1.15s/it]\u001b[A\n",
            "Iteration:  97% 634/654 [11:44<00:22,  1.12s/it]\u001b[A\n",
            "Iteration:  97% 635/654 [11:45<00:20,  1.10s/it]\u001b[A\n",
            "Iteration:  97% 636/654 [11:46<00:19,  1.09s/it]\u001b[A\n",
            "Iteration:  97% 637/654 [11:47<00:18,  1.09s/it]\u001b[A\n",
            "Iteration:  98% 638/654 [11:48<00:17,  1.08s/it]\u001b[A\n",
            "Iteration:  98% 639/654 [11:49<00:16,  1.08s/it]\u001b[A\n",
            "Iteration:  98% 640/654 [11:50<00:15,  1.07s/it]\u001b[A\n",
            "Iteration:  98% 641/654 [11:51<00:13,  1.07s/it]\u001b[A\n",
            "Iteration:  98% 642/654 [11:52<00:12,  1.08s/it]\u001b[A\n",
            "Iteration:  98% 643/654 [11:54<00:12,  1.10s/it]\u001b[A\n",
            "Iteration:  98% 644/654 [11:55<00:11,  1.13s/it]\u001b[A\n",
            "Iteration:  99% 645/654 [11:56<00:10,  1.15s/it]\u001b[A\n",
            "Iteration:  99% 646/654 [11:57<00:09,  1.17s/it]\u001b[A\n",
            "Iteration:  99% 647/654 [11:58<00:08,  1.17s/it]\u001b[A\n",
            "Iteration:  99% 648/654 [11:59<00:06,  1.14s/it]\u001b[A\n",
            "Iteration:  99% 649/654 [12:00<00:05,  1.12s/it]\u001b[A\n",
            "Iteration:  99% 650/654 [12:02<00:04,  1.10s/it]\u001b[A\n",
            "Iteration: 100% 651/654 [12:03<00:03,  1.09s/it]\u001b[A\n",
            "Iteration: 100% 652/654 [12:04<00:02,  1.09s/it]\u001b[A\n",
            "Iteration: 100% 653/654 [12:05<00:01,  1.08s/it]\u001b[A\n",
            "Iteration: 100% 654/654 [12:05<00:00,  1.11s/it]\n",
            "11/11/2025 10:10:54 - INFO - __main__ -   ***** Eval results *****\n",
            "11/11/2025 10:10:54 - INFO - __main__ -     epoch = 1\n",
            "\n",
            "11/11/2025 10:10:54 - INFO - __main__ -     global_step = 654\n",
            "\n",
            "11/11/2025 10:10:54 - INFO - __main__ -     loss = 0.1793757953313649\n",
            "\n",
            "11/11/2025 10:10:54 - INFO - __main__ -     test_loss = 0.17218341497504266\n",
            "\n",
            "11/11/2025 10:10:54 - INFO - __main__ -     ner_test_loss = 0.5876884170738627\n",
            "\n",
            "11/11/2025 10:10:54 - INFO - __main__ -     test_accuracy = 0.958656330749354\n",
            "\n",
            "Epoch: 100% 1/1 [13:01<00:00, 781.63s/it]\n"
          ]
        }
      ]
    }
  ]
}